{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAR Transformer XL Trainer\n",
    "\n",
    "This notebook is to facilitate training on Google colab, so that you can use a GPU/TPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colab specific setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Jmkernes/PAR-Transformer-XL.git\n",
    "%cd PAR-Transformer-XL/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tensorboard. Re-run this cell before every run to reload tensorboard.\n",
    "\n",
    "This will setup the metric tracking. It's not required, as the code will print out the loss every 100 steps and print to a log file. But, this will tell you additional things like learning rate, perplexity and validation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r logs\n",
    "!rm -r plots\n",
    "!mkdir logs\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model\n",
    "\n",
    "Adjust the parameters in the base_model script if you want to alter the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./base_model.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Save results\n",
    "\n",
    "The checkpoints file can be a lot of data, so it's advised to not zip the whole thing (which is why it's commented out) but just take which checkpoints you want.\n",
    "\n",
    "If the code runs to completion (about 37m on a single GPU with default model settings), then you also have the option of downloading a .savedmodel file, which can be loaded into a fully functional model by executing ``` tf.keras.models.load_model('saved_models')```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "!zip -r logs.zip logs\n",
    "!zip -r plots.zip plots\n",
    "# !zip -r checkpoints.zip checkpoints\n",
    "\n",
    "# files.download('plots.zip')\n",
    "# files.download('logs.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive session\n",
    "\n",
    "Since this is a notebook, you can load in different checkpoints of the model (or the final version) and play around with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "import matplotlib.pyplot as plt\n",
    "from data_utils import DataManager\n",
    "from utils import visualize_pi_weights\n",
    "from par_model import PARTransformerXL\n",
    "from par_model import create_lookahead_mask, positional_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below will work to load in from checkpoint. You have to \n",
    "\n",
    "1) recreate an identical model with the same architecture\n",
    "\n",
    "2) create a checkpoint object with parameter model=model. The key here was decided when the first model was checkpointed, i.e., that the model should always be called model.\n",
    "\n",
    "3) restore the checkpoint object with a checkpoint path ckpt.restore(PATH). This will automatically change the value of model globally, i.e. ckpt doesn't keep a copy of model, it keeps a reference.\n",
    "\n",
    "All that is in the load_from_checkpoint path. Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_checkpoint(ckpt_path):\n",
    "    with open(ckpt_path+'/config.json', 'r') as file:\n",
    "        config = json.loads(file.readline())\n",
    "    model = PARTransformerXL(**config)\n",
    "    ckpt = tf.train.Checkpoint(model=model)\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, ckpt_path, 5)\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    return model\n",
    "\n",
    "def load_from_savedmodel(path):\n",
    "    return tf.keras.models.load_model(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
