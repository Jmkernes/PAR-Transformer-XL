{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "import matplotlib.pyplot as plt\n",
    "from data_utils import DataManager\n",
    "from par_model import PARTransformerXL\n",
    "from vanilla_transformer import VanillaPARtransformer\n",
    "from par_model import create_lookahead_mask, positional_encoding\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "config = {\n",
    "    'd_model':128, \n",
    "    'num_heads':4, \n",
    "    'd_ffn':512,\n",
    "    'num_layers':12, \n",
    "    'vocab_size':12000,\n",
    "    'max_position':512, \n",
    "    'dropout_rate':0.1, \n",
    "    'cutoffs':None, \n",
    "    'proj_factor':4, \n",
    "    'proj_dims':None,\n",
    "}\n",
    "mpos = config['max_position']\n",
    "pos_enc = positional_encoding(mpos, config['d_model'])\n",
    "lookahead_mask = create_lookahead_mask(mpos, mpos)\n",
    "model = VanillaPARtransformer(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = pos_enc[:,:32,:]\n",
    "mask = lookahead_mask[:,:,:32,:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   2374\u001b[0m     \"\"\"\n\u001b[1;32m   2375\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2376\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   2377\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2378\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = pos_enc[:,:32,:]\n",
    "mask = lookahead_mask[:,:,:32,:32]\n",
    "train_loss = tf.keras.metrics.Mean()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "tau = 10.0\n",
    "eta = 0.1**(1/1000.)\n",
    "\n",
    "@tf.function(input_signature=[\n",
    "    tf.TensorSpec(shape=(32,32), dtype=tf.int32),\n",
    "     tf.TensorSpec(shape=(32,32), dtype=tf.int32),\n",
    "    tf.TensorSpec(shape=(), dtype=tf.float32)\n",
    "])\n",
    "def train_step(inp, labels, tau):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = model(inp, position=R, labels=labels, mask=mask, tau=tau)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------  Epoch 1  ----------\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tau:0', 'tau:0', 'tau:0', 'tau:0', 'tau:0', 'tau:0', 'tau:0', 'tau:0', 'tau:0', 'tau:0', 'tau:0', 'tau:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tau:0', 'tau:0', 'tau:0', 'tau:0', 'tau:0', 'tau:0', 'tau:0', 'tau:0', 'tau:0', 'tau:0', 'tau:0', 'tau:0'] when minimizing the loss.\n",
      "Iteration 574/2827: [==>........] 1.50 it/s. Est: 25m 07s Loss: 6.129\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-8a0724e9e67d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "tot = 2827\n",
    "history = {'loss':[], 'tau':[]}\n",
    "\n",
    "tau = 1.0\n",
    "eta = 0.1**(1/2200.)\n",
    "for epoch in range(EPOCHS):\n",
    "    print('-'*10,f' Epoch {epoch+1} ', '-'*10)\n",
    "    start = time.time()\n",
    "    train_loss.reset_states()\n",
    "    for step, (inp, lbl) in enumerate(train_ds):\n",
    "        loss = train_step(inp, lbl, tau)\n",
    "        history['loss'].append(loss)\n",
    "        diff = (time.time()-start)/(step+1)\n",
    "        printBar(step, tot, diff, loss.numpy())\n",
    "        tau *= eta\n",
    "        history['tau'].append(tau)\n",
    "            \n",
    "train(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "config = {\n",
    "    'd_model':128, \n",
    "    'num_heads':4, \n",
    "    'd_ffn':512,\n",
    "    'num_layers':12, \n",
    "    'vocab_size':12000,\n",
    "    'max_position':512, \n",
    "    'dropout_rate':0.1, \n",
    "    'cutoffs':[500, 2500, 12000], \n",
    "    'proj_factor':4, \n",
    "    'proj_dims':None,\n",
    "}\n",
    "\n",
    "from vanilla_transformer import Transformer12Layer\n",
    "model = Transformer12Layer(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer12_layer\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  1536000   \n",
      "_________________________________________________________________\n",
      "encoder_layer (EncoderLayer) multiple                  198272    \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (EncoderLaye multiple                  198272    \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (EncoderLaye multiple                  198272    \n",
      "_________________________________________________________________\n",
      "encoder_layer_3 (EncoderLaye multiple                  198272    \n",
      "_________________________________________________________________\n",
      "adaptive_softmax (AdaptiveSo multiple                  221418    \n",
      "_________________________________________________________________\n",
      "inp_dropout (Dropout)        multiple                  0         \n",
      "=================================================================\n",
      "Total params: 2,550,506\n",
      "Trainable params: 2,550,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model(inp, R)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "learning_rate = CustomSchedule(128, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------  Epoch 1  ----------\n",
      "Iteration 2827/2827: [==========>] 5.42 it/s. Est: 00m 00s Loss: 4.865 5.49 it/s. Est: 03m 28s Loss: 5.169[======>....] 5.46 it/s. Est: 03m 22s Loss: 5.1555.42 it/s. Est: 02m 14s Loss: 5.034\n",
      "----------  Epoch 2  ----------\n",
      "Iteration 141/2827: [>..........] 5.14 it/s. Est: 08m 42s Loss: 4.289Loss: 4.272\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-e1e05da2089e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "R = pos_enc[:,:32,:]\n",
    "mask = lookahead_mask[:,:,:32,:32]\n",
    "train_loss = tf.keras.metrics.Mean()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "@tf.function(input_signature=[\n",
    "    tf.TensorSpec(shape=(32,32), dtype=tf.int32),\n",
    "     tf.TensorSpec(shape=(32,32), dtype=tf.int32)\n",
    "])\n",
    "def train_step(inp, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = model(inp, position=R, labels=labels, mask=mask)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    return train_loss.result()\n",
    "\n",
    "EPOCHS = 2\n",
    "tot = 2827\n",
    "history = {'loss':[]}\n",
    "for epoch in range(EPOCHS):\n",
    "    print('-'*10,f' Epoch {epoch+1} ', '-'*10)\n",
    "    start = time.time()\n",
    "    train_loss.reset_states()\n",
    "    for step, (inp, lbl) in enumerate(train_ds):\n",
    "        loss = train_step(inp, lbl)\n",
    "        history['loss'].append(loss)\n",
    "        diff = (time.time()-start)/(step+1)\n",
    "        printBar(step, tot, diff, loss.numpy())\n",
    "            \n",
    "train(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbbddb00880>]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'][50:])\n",
    "# plt.plot(history['tau'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=4.7851562>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = tf.equal(tf.cast(tf.argmax(model(inp, R, training=False), -1),tf.int32), labels)\n",
    "acc = 100*tf.reduce_mean(tf.cast(acc, tf.float32))\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b''>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.tokenizer.detokenize([5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: [0.32119352 0.32047126 0.35673234]\n",
      "Layer 2: [0.3197162  0.34020415 0.35368592]\n",
      "Layer 3: [0.35318667 0.28377616 0.34028876]\n",
      "Layer 4: [0.3391504  0.30977973 0.3718491 ]\n",
      "Layer 1: 1.0\n",
      "Layer 2: 1.0\n",
      "Layer 3: 1.0\n",
      "Layer 4: 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,6):\n",
    "    print(f\"Layer {i-1}: {model.layers[i].pi.numpy()}\")\n",
    "    \n",
    "for i in range(2,6):\n",
    "    print(f\"Layer {i-1}: {model.layers[i].tau.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 13.333333333333334, 3)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4*5, 2*20/3, 13//4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 100\n",
    "nt = int(0.66*n)\n",
    "5*nf + nt = n\n",
    "8*n//3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so basically there are three equations. 1)tot layers 2) confine to first 1/3 3)enfore that n_f fills the rest\n",
    "\n",
    "$$ n_f = 5 n_t $$\n",
    "$$n_t + n_f = N$$\n",
    "$$n_t + x = 2N/3$$\n",
    "\n",
    "Ok so solve these we get $n_t = N/6$ and $x=N/2 = (n_f+n_t)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 4\n",
    "N = 24\n",
    "int(0.66*N)//(4+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100/100: [==========>] 84.40 it/s. Est: 00m 00s Loss: 0.500\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def printBar(step, tot, diff, loss):\n",
    "    num_eq = int(10*(step+1)/tot)\n",
    "    num_pd = 10-num_eq\n",
    "    bar = '['+'='*num_eq+'>'+'.'*num_pd+']'\n",
    "    time_left = (tot-step)*diff\n",
    "    m = int(time_left)//60\n",
    "    s = int(time_left)%60\n",
    "    iter_message = f\"Iteration {step+1:02d}/{tot}:\"\n",
    "    time_message = f\"{1/diff:.2f} it/s. Est: {m:02d}m {s:02d}s\"\n",
    "    loss_message = f\"Loss: {loss:.3f}\"\n",
    "    end = '\\r' if step<tot-1 else '\\n'\n",
    "    print(iter_message, bar, time_message, loss_message, end=end)\n",
    "    \n",
    "start = time.time()\n",
    "for i in range(100):\n",
    "    time.sleep(0.01)\n",
    "    x = 5/np.sqrt(i+1)\n",
    "    diff = (time.time()-start)/(i+1)\n",
    "    printBar(i, 100, diff, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wikitext2_bsz32_seqlen32_tfrecords_valid',\n",
       " 'wikitext-2',\n",
       " 'wikitext2_bsz32_seqlen32_tfrecords_train',\n",
       " 'wikitext2_bsz32_seqlen32_tfrecords_test']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer from wiki2_12k.model...\n",
      "Loading tfrecords from directory\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'sp_model_prefix':'wiki2_12k', \n",
    "    'tfrecords_directory': 'data/wikitext2_bsz32_seqlen32_tfrecords_train'\n",
    "}\n",
    "dm = DataManager.initialize_from_tfrecord(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=12000>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.tokenizer.vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'd_model': 128, \n",
    "    'num_heads': 4, \n",
    "    'max_position': 64,  \n",
    "    'd_ffn': 512, \n",
    "    'num_layers': 4, \n",
    "    'mem_len': 32, \n",
    "    'vocab_size': 12000,\n",
    "    'dropout_rate': 0.1, \n",
    "    'cutoffs': [250, 2500, 12000], \n",
    "    'proj_factor':4,\n",
    "    'proj_dims':None\n",
    "}\n",
    "\n",
    "model = PARTransformerXL(**model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = dm.tokenizer.vocab_size().numpy()\n",
    "BATCH_SIZE = dm.batch_size\n",
    "SEQ_LEN = dm.seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"par_transformer_xl\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  1536000   \n",
      "_________________________________________________________________\n",
      "adaptive_softmax (AdaptiveSo multiple                  197418    \n",
      "_________________________________________________________________\n",
      "stochastic_block (Stochastic multiple                  215044    \n",
      "_________________________________________________________________\n",
      "stochastic_block_1 (Stochast multiple                  215044    \n",
      "_________________________________________________________________\n",
      "stochastic_block_2 (Stochast multiple                  215044    \n",
      "_________________________________________________________________\n",
      "stochastic_block_3 (Stochast multiple                  215044    \n",
      "_________________________________________________________________\n",
      "inp_dropout (Dropout)        multiple                  0         \n",
      "=================================================================\n",
      "Total params: 2,593,594\n",
      "Trainable params: 2,593,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = tf.random.uniform((BATCH_SIZE, SEQ_LEN), 0, VOCAB_SIZE, tf.int32)\n",
    "logits, mems = model(inp)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-c790a2235ee2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "mems[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dm.get_inp_tar_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 32), dtype=int32, numpy=\n",
       " array([[   5,   21, 2191, ...,   36,  620,  660],\n",
       "        [   8,  225, 4811, ...,   24,    7, 3278],\n",
       "        [ 330,   18, 2847, ..., 8634,  689,    7],\n",
       "        ...,\n",
       "        [  12,   14,   13, ..., 1487,  230,   28],\n",
       "        [   3,    5,    3, ..., 1129,  852,    7],\n",
       "        [6030,   23, 6257, ...,  141, 6622,   19]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(32, 32), dtype=int32, numpy=\n",
       " array([[  21, 2191,  640, ...,  620,  660,    5],\n",
       "        [ 225, 4811,  855, ...,    7, 3278,  595],\n",
       "        [  18, 2847,    7, ...,  689,    7,   41],\n",
       "        ...,\n",
       "        [  14,   13,   12, ...,  230,   28,  127],\n",
       "        [   5,    3,    5, ...,  852,    7,   16],\n",
       "        [  23, 6257,   10, ..., 6622,   19, 1937]], dtype=int32)>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_signature = [\n",
    "#     tf.TensorSpec(shape=(BATCH_SIZE, SEQ_LEN), dtype=tf.int32),\n",
    "#     [tf.TensorSpec(shape=(BATCH_SIZE, SEQ_LEN), dtype=tf.int32) \n",
    "#      for _ in range(model_config['num_layers'])],\n",
    "#     tf.TensorSpec(shape=(BATCH_SIZE, SEQ_LEN), dtype=tf.int32)\n",
    "# ]\n",
    "# @tf.function(input_signature=input_signature)\n",
    "@tf.function\n",
    "def train_step(inp, labels, mems):\n",
    "    model(x=inp, x_mems=mems, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, labels = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.70710677>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.70710677>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.rsqrt(2.), 1/tf.math.sqrt(2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute ConcatV2 as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:ConcatV2] name: concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-f166d4293633>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/NLP/transformer-xl/PARtransformer/par_model.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, x_mems, tau, labels, training, pad_mask)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mnew_mems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0mnew_mem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_mem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m             \u001b[0mnew_mems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoch_blks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/NLP/transformer-xl/PARtransformer/par_model.py\u001b[0m in \u001b[0;36m_get_next_mem\u001b[0;34m(self, x, x_mem, mem_len)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mx_mem\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmem_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_mem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmem_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# don't backpropagate to cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1675\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n\u001b[1;32m   1676\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1677\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute ConcatV2 as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:ConcatV2] name: concat"
     ]
    }
   ],
   "source": [
    "logits, mems = model(inp, labels, mems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[\n",
    "    tf.TensorSpec(shape=(), dtype=tf.float32),\n",
    "    [tf.TensorSpec(shape=(), dtype=tf.float32) for _ in range(2)]\n",
    "] )\n",
    "def my_func(x, y):\n",
    "    res = 0\n",
    "    for i in range(2):\n",
    "        res = res + y[i]\n",
    "    return res + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=14.0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant(5.)\n",
    "y = [tf.constant(3.), tf.constant(6.)]\n",
    "my_func(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
