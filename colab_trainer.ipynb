{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tensorflow_text\n",
    "!git clone https://github.com/Jmkernes/PAR-Transformer-XL.git\n",
    "%cd PAR-Transformer-XL/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabled check-numerics callback in thread MainThread\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabled check-numerics callback in thread MainThread\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.info(\"\\n\\n~~~~~~~~ Importing Modules ~~~~~~~~\\n\")\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "import matplotlib.pyplot as plt\n",
    "from data_utils import DataManager\n",
    "from utils import print_bar, visualize_pi_weights\n",
    "from par_model import PARTransformerXL\n",
    "from par_model import create_lookahead_mask, positional_encoding\n",
    "\n",
    "tf.debugging.enable_check_numerics()\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "def load_datasets(train, val, test):\n",
    "    \"\"\"Load the wikitext2 train, validation and test data\"\"\"\n",
    "    logging.info(f\"\\nLoading training data from: {train}\")\n",
    "    config = {'tfrecords_directory': train,'sp_model_prefix': 'wiki2_12k'}\n",
    "    train_dm = DataManager.initialize_from_tfrecord(config)\n",
    "\n",
    "    logging.info(f\"\\nLoading validation data from: {val}\")\n",
    "    config['tfrecords_directory'] = val\n",
    "    valid_dm = DataManager.initialize_from_tfrecord(config)\n",
    "\n",
    "    logging.info(f\"\\nLoading testing data from: {test}\\n\")\n",
    "    config['tfrecords_directory'] = test\n",
    "    test_dm = DataManager.initialize_from_tfrecord(config)\n",
    "\n",
    "    return train_dm, valid_dm, test_dm\n",
    "\n",
    "class TransformerSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "class CosineSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, max_lr, decay_steps, warmup_steps=4000, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.max_lr = max_lr\n",
    "        self.decay_steps = decay_steps\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.pi = 3.1415927\n",
    "    def __call__(self, step):\n",
    "        linear = self.max_lr*(step/self.warmup_steps)\n",
    "        cosine = 0.5*self.max_lr*(1+tf.math.cos(self.pi*tf.math.maximum(step-self.warmup_steps, 0)/self.decay_steps))\n",
    "        return tf.math.minimum(linear, cosine)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbb48d82a30>]"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = CosineSchedule(1e-3, 4000, 2000)\n",
    "plt.plot(learning_rate(tf.range(6000.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpointing and tensorboard params\n",
    "model_name='base'#datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# data params\n",
    "train_directory='data/wikitext2_bsz32_seqlen32_tfrecords_train'\n",
    "valid_directory='data/wikitext2_bsz32_seqlen32_tfrecords_valid'\n",
    "test_directory='data/wikitext2_bsz32_seqlen32_tfrecords_test'\n",
    "\n",
    "# model params\n",
    "# d_model=256\n",
    "# num_heads=8\n",
    "# d_ffn=1024\n",
    "# num_layers=12\n",
    "# mem_len=32\n",
    "# dropout_rate=0.1\n",
    "# cutoffs=[250, 2500]\n",
    "# proj_factor=4\n",
    "# proj_dims=[]\n",
    "\n",
    "# small version for testing\n",
    "d_model=64\n",
    "num_heads=2\n",
    "d_ffn=128\n",
    "num_layers=4\n",
    "mem_len=32\n",
    "dropout_rate=0.1\n",
    "cutoffs=[250, 2500]\n",
    "proj_factor=2\n",
    "proj_dims=[]\n",
    "\n",
    "# learning params\n",
    "warmup_steps=4000\n",
    "tau_start=2.0\n",
    "tau_end=0.2\n",
    "epochs=5\n",
    "tau_is_trainable=False\n",
    "opt_name='adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take care of some flags logic beyond simple constraints.\n",
    "if d_model%num_heads:\n",
    "    raise ValueError('Number of heads must divide d_model')\n",
    "\n",
    "train_dm, valid_dm, test_dm = load_datasets(train_directory, valid_directory, test_directory)\n",
    "\n",
    "## Set global constants inferred from the training data.\n",
    "BATCH_SIZE = train_dm.batch_size\n",
    "SEQ_LEN = train_dm.seq_len\n",
    "VOCAB_SIZE = train_dm.tokenizer.vocab_size().numpy()\n",
    "DATASET_SIZE = train_dm.ds_size.numpy()\n",
    "MAX_POSITION = max(512, mem_len+SEQ_LEN)\n",
    "\n",
    "# Take care of additional constraints on inputs that needed the vocab size\n",
    "if any([z>=VOCAB_SIZE for z in cutoffs]) or len(set(cutoffs))!=len(cutoffs):\n",
    "    raise ValueError(\"Cutoffs must not exceed {VOCAB_SIZE} or contain duplicates.\")\n",
    "if cutoffs:\n",
    "    cutoffs.sort()\n",
    "    cutoffs.append(VOCAB_SIZE)\n",
    "\n",
    "### Define learning rate schedule and simulated annealing schedule for gumbel softmax temperature tau.\n",
    "logging.info(f\"\\n\\nInitializing {opt_name} optimizer with {warmup_steps} warmup steps.\")\n",
    "learning_rate = CosineSchedule(max_lr=5e-4, warmup_steps=4000, decay_steps=DATASET_SIZE*epochs-4000)\n",
    "optimizer = tf.keras.optimizers.get(opt_name)\n",
    "optimizer.learning_rate = learning_rate\n",
    "\n",
    "if tau_is_trainable:\n",
    "    logging.info(f\"\\n\\nInitializing exponential tau decay: {tau_start}-->{tau_end}.\\n\")\n",
    "tau = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=tau_start,\n",
    "    decay_steps=DATASET_SIZE*epochs,\n",
    "    decay_rate=tau_end\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the model\n",
    "tf.keras.backend.clear_session()\n",
    "config = {\n",
    "    'd_model': d_model,\n",
    "    'num_heads': num_heads,\n",
    "    'max_position': MAX_POSITION,\n",
    "    'd_ffn': d_ffn,\n",
    "    'num_layers': num_layers,\n",
    "    'mem_len': mem_len,\n",
    "    'vocab_size': VOCAB_SIZE,\n",
    "    'dropout_rate': dropout_rate,\n",
    "    'cutoffs': cutoffs,\n",
    "    'proj_factor': proj_factor,\n",
    "    'proj_dims': proj_dims,\n",
    "}\n",
    "logging.info(\"\\n\\nInitializing model...\")\n",
    "logging.info(\"Model parameters:\")\n",
    "logging.info(config)\n",
    "pos_enc = positional_encoding(MAX_POSITION, d_model)\n",
    "lookahead_mask = create_lookahead_mask(MAX_POSITION, MAX_POSITION)\n",
    "model = PARTransformerXL(**config)\n",
    "\n",
    "# Build model by feeding in sample training data\n",
    "x_temp, y_temp = next(iter(train_dm.get_inp_tar_pairs()))\n",
    "model(x_temp, None, labels=y_temp, training=False)\n",
    "\n",
    "# make tau untrainable\n",
    "if not tau_is_trainable:\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'tau'):\n",
    "            layer.tau = tf.cast(tf.constant(1.), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"par_transformer_xl\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  768000    \n",
      "_________________________________________________________________\n",
      "adaptive_softmax (AdaptiveSo multiple                  255250    \n",
      "_________________________________________________________________\n",
      "stochastic_block (Stochastic multiple                  37763     \n",
      "_________________________________________________________________\n",
      "stochastic_block_1 (Stochast multiple                  37763     \n",
      "_________________________________________________________________\n",
      "stochastic_block_2 (Stochast multiple                  37763     \n",
      "_________________________________________________________________\n",
      "stochastic_block_3 (Stochast multiple                  37763     \n",
      "_________________________________________________________________\n",
      "inp_dropout (Dropout)        multiple                  0         \n",
      "=================================================================\n",
      "Total params: 1,174,302\n",
      "Trainable params: 1,174,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# print out model summary\n",
    "logging.info(\"\\nModel summary:\")\n",
    "logging.info(model.summary())\n",
    "\n",
    "# Define metrics\n",
    "train_loss = tf.keras.metrics.Mean()\n",
    "valid_loss = tf.keras.metrics.Mean()\n",
    "train_perp = tf.keras.metrics.Mean()\n",
    "valid_perp = tf.keras.metrics.Mean()\n",
    "\n",
    "logging.info(\"\\n\\nDefining training and evaluation steps...\")\n",
    "# Define the training and evaluation steps via tf functions\n",
    "@tf.function\n",
    "def train_step(inp, x_mems, labels, tau):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss, mems = model(inp, x_mems=x_mems, labels=labels, training=True, tau=tau)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_perp(tf.math.exp(loss))\n",
    "    return mems\n",
    "\n",
    "@tf.function\n",
    "def evaluation_step(x, x_mems, labels, tau):\n",
    "    loss, mems = model(x, x_mems=x_mems, labels=labels, tau=tau, training=False)\n",
    "    valid_loss(loss)\n",
    "    valid_perp(tf.math.exp(loss))\n",
    "    return mems\n",
    "\n",
    "def evaluation(dataset, tau):\n",
    "    x_mems = None\n",
    "    for x, lbl in dataset:\n",
    "        x_mems = evaluation_step(x, x_mems, lbl, tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up TensorBoard\n",
    "logging.info(\"\\n\\nInitializing TensorBoard...\")\n",
    "train_log_dir = './logs/' + model_name + '/train'\n",
    "test_log_dir = './logs/' + model_name + '/test'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "\n",
    "# # TODO: FIGURE OUT WHAT TO DO HERE, HOW TO LOAD TensorBoard\n",
    "# Maybe try os.system()? Or push this into another loading script? idk\n",
    "# os.system('tensorboard --logdir ./logs')\n",
    "\n",
    "# Configure datasets for training\n",
    "logging.info(\"\\n\\nConfiguring datasets for training. Caching, prefetching...\")\n",
    "glob_step = tf.Variable(0, dtype=tf.int64) # This will break tf.summary if we use int32\n",
    "train_ds = train_dm.get_inp_tar_pairs().cache().prefetch(tf.data.AUTOTUNE)\n",
    "valid_ds = valid_dm.get_inp_tar_pairs().prefetch(tf.data.AUTOTUNE)\n",
    "iterator=iter(train_ds)\n",
    "\n",
    "# Set up checkpointing to periodically save the model every epoch\n",
    "checkpoint_path = \"./checkpoints/train/\"+model_name\n",
    "logging.info(f\"\\n\\nInitializing checkpoints. Models will be saved to {checkpoint_path}\")\n",
    "ckpt = tf.train.Checkpoint(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    glob_step=glob_step,\n",
    "    iterator=iterator\n",
    ")\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    try:\n",
    "        ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "        logging.info('Latest checkpoint restored!!')\n",
    "    except:\n",
    "        logging.warning(\"Model may have changed, could not restore checkpoint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log initial checkpoint\n",
    "ckpt_save_path = ckpt_manager.save()\n",
    "logging.info(f'Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Epoch 1/5 ----------\n",
      "Iteration 50/50: [==========>] 4.45 it/s. Est: 00m 00s Loss: 8.261\n",
      "---------- Epoch 2/5 ----------\n",
      "Iteration 50/50: [==========>] 3.70 it/s. Est: 00m 00s Loss: 8.177\n",
      "---------- Epoch 3/5 ----------\n",
      "Iteration 50/50: [==========>] 3.64 it/s. Est: 00m 00s Loss: 8.053\n",
      "---------- Epoch 4/5 ----------\n",
      "Iteration 50/50: [==========>] 3.71 it/s. Est: 00m 00s Loss: 7.865\n",
      "---------- Epoch 5/5 ----------\n",
      "Iteration 50/50: [==========>] 3.87 it/s. Est: 00m 00s Loss: 7.647\n"
     ]
    }
   ],
   "source": [
    "# Run the actual training loop!\n",
    "logging.info(\"\\n\\n~~~~~~~~~~ Beginning training ~~~~~~~~~~\")\n",
    "for epoch in range(epochs):\n",
    "\n",
    "#     logging.info('-'*10+f' Epoch {epoch+1}/{epochs} '+'-'*10)\n",
    "    print('-'*10+f' Epoch {epoch+1}/{epochs} '+'-'*10)\n",
    "    start = time.time()\n",
    "    for x in [train_loss, valid_loss, train_perp, valid_perp]:\n",
    "        x.reset_states()\n",
    "    mems = None\n",
    "\n",
    "    for step, (inp, lbl) in enumerate(train_ds.take(50)):\n",
    "\n",
    "        mems = train_step(inp, mems, lbl, tau(glob_step))\n",
    "\n",
    "        diff = (time.time()-start)/(step+1)\n",
    "        print_bar(step, 50, diff, train_loss.result().numpy())\n",
    "\n",
    "        with train_summary_writer.as_default():\n",
    "            tf.summary.scalar('train_loss', train_loss.result(), step=glob_step)\n",
    "            tf.summary.scalar('train_perp', train_perp.result(), step=glob_step)\n",
    "            tf.summary.scalar('tau', tau(glob_step), step=glob_step)\n",
    "        glob_step.assign_add(1)\n",
    "\n",
    "    evaluation(valid_ds.take(5), tau(glob_step))\n",
    "    with test_summary_writer.as_default():\n",
    "        tf.summary.scalar('valid_loss', valid_loss.result(), step=glob_step)\n",
    "        tf.summary.scalar('valid_perp', valid_perp.result(), step=glob_step)\n",
    "\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    logging.info(f'Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}')\n",
    "    \n",
    "    visualize_pi_weights(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c9a7cee970e5c7a1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c9a7cee970e5c7a1\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_pi_weights(model)\n",
    "visualize_pi_weights(model)\n",
    "visualize_pi_weights(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint                 ckpt-4.index\r\n",
      "ckpt-2.data-00000-of-00001 ckpt-5.data-00000-of-00001\r\n",
      "ckpt-2.index               ckpt-5.index\r\n",
      "ckpt-3.data-00000-of-00001 ckpt-6.data-00000-of-00001\r\n",
      "ckpt-3.index               ckpt-6.index\r\n",
      "ckpt-4.data-00000-of-00001\r\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoints/train/base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in a model from checkpoint\n",
    "\n",
    "new_model = PARTransformerXL(**config)\n",
    "new_model.build(input_shape=[32, 32])\n",
    "# make tau untrainable\n",
    "if not tau_is_trainable:\n",
    "    for layer in new_model.layers:\n",
    "        if hasattr(layer, 'tau'):\n",
    "            layer.tau = tf.cast(tf.constant(1.), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fbb85f956a0>"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = tf.train.Checkpoint(\n",
    "    model=new_model\n",
    ")\n",
    "ckpt.restore(ckpt_manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights 0: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 1: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 2: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 3: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 4: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 5: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 6: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 7: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 8: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 9: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 10: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 11: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 12: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 13: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 14: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 15: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 16: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 17: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 18: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 19: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 20: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 21: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 22: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 23: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 24: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 25: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 26: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 27: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 28: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 29: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 30: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 31: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 32: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 33: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 34: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 35: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 36: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 37: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 38: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 39: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 40: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 41: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 42: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 43: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 44: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 45: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 46: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 47: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 48: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 49: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 50: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 51: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 52: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 53: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 54: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 55: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 56: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 57: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 58: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 59: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 60: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 61: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 62: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 63: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 64: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 65: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 66: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 67: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 68: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 69: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 70: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 71: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 72: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 73: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 74: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 75: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 76: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 77: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n",
      "Weights 78: ndarray<tf.Tensor(True, shape=(), dtype=bool)>\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model.weights)):\n",
    "    print(f\"Weights {i}: {tf.experimental.numpy.allclose(new_model.weights[i], model.weights[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function DataManager.get_inp_tar_pairs.<locals>.<lambda> at 0x7fbb8f5b0820> and will run it as-is.\n",
      "Cause: could not parse the source code of <function DataManager.get_inp_tar_pairs.<locals>.<lambda> at 0x7fbb8f5b0820>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function DataManager.get_inp_tar_pairs.<locals>.<lambda> at 0x7fbb8f5b0820> and will run it as-is.\n",
      "Cause: could not parse the source code of <function DataManager.get_inp_tar_pairs.<locals>.<lambda> at 0x7fbb8f5b0820>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_temp, y_temp = next(iter(train_dm.get_inp_tar_pairs()))\n",
    "# new_model(x_temp, None, labels=y_temp, training=False)\n",
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r checkpoints/\n",
    "!rm -r logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_weights = model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2827"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dm.ds_size.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'write'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-447-8570658c2d89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpprint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model parameters:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pprint.py\u001b[0m in \u001b[0;36mpprint\u001b[0;34m(object, stream, indent, width, depth, compact, sort_dicts)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         compact=compact, sort_dicts=sort_dicts)\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m def pformat(object, indent=1, width=80, depth=None, *,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pprint.py\u001b[0m in \u001b[0;36mpprint\u001b[0;34m(self, object)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pprint.py\u001b[0m in \u001b[0;36m_format\u001b[0;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobjid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0m_dispatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'write'"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(\"Model parameters:\\n\",config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the wikitext2 train, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer from wiki2_12k.model...\n",
      "Loading tfrecords from directory\n",
      "WARNING:tensorflow:AutoGraph could not transform <function load_tfrecord_ds_from_files.<locals>.<lambda> at 0x7fbbdb18e160> and will run it as-is.\n",
      "Cause: could not parse the source code of <function load_tfrecord_ds_from_files.<locals>.<lambda> at 0x7fbbdb18e160>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function load_tfrecord_ds_from_files.<locals>.<lambda> at 0x7fbbdb18e160> and will run it as-is.\n",
      "Cause: could not parse the source code of <function load_tfrecord_ds_from_files.<locals>.<lambda> at 0x7fbbdb18e160>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function load_tfrecord_ds_from_files.<locals>.<lambda> at 0x7fbbd9971940> and will run it as-is.\n",
      "Cause: could not parse the source code of <function load_tfrecord_ds_from_files.<locals>.<lambda> at 0x7fbbd9971940>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function load_tfrecord_ds_from_files.<locals>.<lambda> at 0x7fbbd9971940> and will run it as-is.\n",
      "Cause: could not parse the source code of <function load_tfrecord_ds_from_files.<locals>.<lambda> at 0x7fbbd9971940>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Loading tokenizer from wiki2_12k.model...\n",
      "Loading tfrecords from directory\n",
      "Loading tokenizer from wiki2_12k.model...\n",
      "Loading tfrecords from directory\n"
     ]
    }
   ],
   "source": [
    "config = {'tfrecords_directory':'data/wikitext2_bsz32_seqlen32_tfrecords_train',\n",
    "                'sp_model_prefix': 'wiki2_12k'}\n",
    "train_dm = DataManager.initialize_from_tfrecord(config)\n",
    "\n",
    "config['tfrecords_directory'] = 'data/wikitext2_bsz32_seqlen32_tfrecords_valid'\n",
    "valid_dm = DataManager.initialize_from_tfrecord(config)\n",
    "\n",
    "config['tfrecords_directory'] = 'data/wikitext2_bsz32_seqlen32_tfrecords_test'\n",
    "test_dm = DataManager.initialize_from_tfrecord(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=2827>"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dm.ds_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "config = {\n",
    "    'd_model':64, \n",
    "    'num_heads':4, \n",
    "    'max_position':512, \n",
    "    'd_ffn':128,\n",
    "    'num_layers':6, \n",
    "    'mem_len':32, \n",
    "    'vocab_size':12000,\n",
    "    'dropout_rate':0.1, \n",
    "    'cutoffs':[250, 2500, 12000], \n",
    "    'proj_factor':2, \n",
    "    'proj_dims':None,\n",
    "}\n",
    "\n",
    "ds_size = train_dm.ds_size\n",
    "max_position = config['max_position']\n",
    "pos_enc = positional_encoding(max_position, config['d_model'])\n",
    "lookahead_mask = create_lookahead_mask(max_position, max_position)\n",
    "model = PARTransformerXL(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"par_transformer_xl\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  768000    \n",
      "_________________________________________________________________\n",
      "adaptive_softmax (AdaptiveSo multiple                  255250    \n",
      "_________________________________________________________________\n",
      "stochastic_block (Stochastic multiple                  37764     \n",
      "_________________________________________________________________\n",
      "stochastic_block_1 (Stochast multiple                  37764     \n",
      "_________________________________________________________________\n",
      "stochastic_block_2 (Stochast multiple                  37764     \n",
      "_________________________________________________________________\n",
      "stochastic_block_3 (Stochast multiple                  37764     \n",
      "_________________________________________________________________\n",
      "stochastic_block_4 (Stochast multiple                  37764     \n",
      "_________________________________________________________________\n",
      "stochastic_block_5 (Stochast multiple                  37764     \n",
      "_________________________________________________________________\n",
      "inp_dropout (Dropout)        multiple                  0         \n",
      "=================================================================\n",
      "Total params: 1,249,834\n",
      "Trainable params: 1,249,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_dm.get_inp_tar_pairs()\n",
    "x, y = next(iter(train_ds))\n",
    "model(x, None, labels=y, training=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create simulated annealing schedule for gumbel softmax tau. We use exponential decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "train_loss = tf.keras.metrics.Mean()\n",
    "valid_loss = tf.keras.metrics.Mean()\n",
    "train_perp = tf.keras.metrics.Mean()\n",
    "valid_perp = tf.keras.metrics.Mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3. Total steps: 8481\n"
     ]
    }
   ],
   "source": [
    "# Define tau schedule, plus must specify total number of global steps\n",
    "EPOCHS = 3\n",
    "tot_steps = int(EPOCHS*ds_size.numpy())\n",
    "\n",
    "tau_is_trainable = False\n",
    "\n",
    "tau = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=2.0,\n",
    "    decay_steps = tot_steps,\n",
    "    decay_rate = 0.1\n",
    ")\n",
    "\n",
    "print(f\"Epochs: {EPOCHS}. Total steps: {tot_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training step and optimizer.\n",
    "\n",
    "learning_rate = CustomSchedule(config['d_model'], 4000)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "@tf.function\n",
    "def train_step(inp, x_mems, labels, tau):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss, mems = model(x, x_mems, labels=labels, training=True, tau=tau)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_perp(tf.math.exp(loss))\n",
    "    return mems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def evaluation_step(x, x_mems, labels, tau):\n",
    "    loss, mems = model(x, x_mems=x_mems, labels=labels, tau=tau, training=False)\n",
    "    perplexity = tf.math.exp(loss)\n",
    "    valid_loss(loss)\n",
    "    valid_perp(perplexity)\n",
    "    return mems\n",
    "\n",
    "def evaluation(dataset, tau):\n",
    "    x_mems = None\n",
    "    for x, lbl in dataset:\n",
    "        x_mems = evaluation_step(x, x_mems, lbl, tau)\n",
    "\n",
    "# @tf.function\n",
    "# def evaluation(dataset, tau):\n",
    "#     mems = None\n",
    "#     for x, lbl in dataset:\n",
    "#         loss, mems = model(x, x_mems=mems, labels=lbl, tau=tau, training=False)\n",
    "#         perplexity = tf.math.exp(loss)\n",
    "#         valid_loss(loss)\n",
    "#         valid_perp(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Checkpoints\n",
    "\n",
    "checkpoint_path = \"./checkpoints/train\"\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    try:\n",
    "        ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "        print ('Latest checkpoint restored!!')\n",
    "    except:\n",
    "        print(\"Model may have changed, could not restore checkpoint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tau untrainable\n",
    "if not tau_is_trainable:\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'tau'):\n",
    "            layer.tau = tf.cast(tf.constant(1.), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Set up TensorBoard\n",
    "\n",
    "%load_ext tensorboard\n",
    "train_log_dir = './logs' + '/train'\n",
    "test_log_dir = './logs' + '/test'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_dm.get_inp_tar_pairs().prefetch(tf.data.AUTOTUNE)\n",
    "valid_ds = valid_dm.get_inp_tar_pairs().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f6d05594fdeaef04\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f6d05594fdeaef04\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------  Epoch 1  ----------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    <ipython-input-448-f7b0885aefec>:9 train_step  *\n        loss, mems = model(x, x_mems, labels=labels, training=True, tau=tau)\n    /Users/jonathankernes/Documents/NLP/transformer-xl/PARtransformer/par_model.py:261 call  *\n        x = self.embed(x)\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__  **\n        outputs = call_fn(inputs, *args, **kwargs)\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/embeddings.py:190 call\n        dtype = K.dtype(inputs)\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:1418 dtype\n        return x.dtype.base_dtype.name\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:798 __getattribute__\n        raise e\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:788 __getattribute__\n        return super(OptimizerV2, self).__getattribute__(name)\n\n    AttributeError: 'RMSprop' object has no attribute 'dtype'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-455-8fd005d892e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mmems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprintBar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    <ipython-input-448-f7b0885aefec>:9 train_step  *\n        loss, mems = model(x, x_mems, labels=labels, training=True, tau=tau)\n    /Users/jonathankernes/Documents/NLP/transformer-xl/PARtransformer/par_model.py:261 call  *\n        x = self.embed(x)\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__  **\n        outputs = call_fn(inputs, *args, **kwargs)\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/embeddings.py:190 call\n        dtype = K.dtype(inputs)\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:1418 dtype\n        return x.dtype.base_dtype.name\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:798 __getattribute__\n        raise e\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:788 __getattribute__\n        return super(OptimizerV2, self).__getattribute__(name)\n\n    AttributeError: 'RMSprop' object has no attribute 'dtype'\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir ./logs\n",
    "history={'loss':[], 'tau':[]}\n",
    "glob_step = 0\n",
    "num_batches = train_dm.ds_size.numpy()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    print('-'*10,f' Epoch {epoch+1} ', '-'*10)\n",
    "    start = time.time()\n",
    "    train_loss.reset_states()\n",
    "    mems = None\n",
    "    for step, (inp, lbl) in enumerate(train_ds):\n",
    "        \n",
    "        mems = train_step(inp, mems, lbl, tau(glob_step))\n",
    "        diff = (time.time()-start)/(step+1)\n",
    "        printBar(step, num_batches, diff, train_loss.result().numpy())\n",
    "                \n",
    "        history['loss'].append(train_loss.result().numpy())\n",
    "        history['tau'].append(tau(glob_step).numpy())\n",
    "        \n",
    "        with train_summary_writer.as_default():\n",
    "            tf.summary.scalar('train_loss', train_loss.result(), step=glob_step)\n",
    "            tf.summary.scalar('train_perp', train_perp.result(), step=glob_step)\n",
    "            tf.summary.scalar('tau', tau(glob_step), step=glob_step)        \n",
    "        glob_step += 1\n",
    "     \n",
    "    evaluation(valid_ds, tau(glob_step))\n",
    "    with test_summary_writer.as_default():\n",
    "        tf.summary.scalar('valid_loss', valid_loss.result(), step=glob_step)\n",
    "        tf.summary.scalar('valid_perp', valid_perp.result(), step=glob_step)\n",
    "    \n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print(f'Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.0>"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau(tf.Variable(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbbd98872e0>]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: [0.32119352 0.32047126 0.35673234]\n",
      "Layer 2: [0.3197162  0.34020415 0.35368592]\n",
      "Layer 3: [0.35318667 0.28377616 0.34028876]\n",
      "Layer 4: [0.3391504  0.30977973 0.3718491 ]\n",
      "Layer 1: 1.0\n",
      "Layer 2: 1.0\n",
      "Layer 3: 1.0\n",
      "Layer 4: 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,6):\n",
    "    print(f\"Layer {i-1}: {model.layers[i].pi.numpy()}\")\n",
    "    \n",
    "for i in range(2,6):\n",
    "    print(f\"Layer {i-1}: {model.layers[i].tau.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpointing and model saving\n",
    "\n",
    "# Initializing a checkpoint manager\n",
    "opt = tf.keras.optimizers.Adam(0.1)\n",
    "dataset = toy_dataset()\n",
    "iterator = iter(dataset)\n",
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=net, iterator=iterator)\n",
    "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)\n",
    "\n",
    "\n",
    "# Restoring from a previous checkpoint\n",
    "ckpt.restore(manager.latest_checkpoint)\n",
    "if manager.latest_checkpoint:\n",
    "    print(f\"Restored from {manager.latest_checkpoint})\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")\n",
    "\n",
    "# Keep track of global step manually in the checkpoint\n",
    "ckpt.step.assign_add(1)\n",
    "if int(ckpt.step) % 10 == 0:\n",
    "  save_path = manager.save()\n",
    "  print(f\"Saved checkpoint for step {int(ckpt.step)}: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 144x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ0AAAG6CAYAAAAS3RPFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd7hcVb3G8e+bk0pCldCkFyO9BZQiROACIoKAYhBEEAQbiliwiyAW7kUsiIAooCCINAUBqaEJSKjSpUQh9GIIISSQ/O4faw3Zmcw5OeuUmTnh/TzPPDl7z5q91+yZefcqeyaKCMzMumtQqytgZgOLQ8PMijg0zKyIQ8PMijg0zKyIQ8PMijg0zKyIQ8PMijg02pSyVtfDrJ58RWj7qIVE+EWxNubQaFOSNgBWBW6PiEmS5DCxEvkkNCgiZvXpdv0+7B+SOoBlI+KJyjoBHcDsiJhdV34osAMwBTgYeD/wFPAGsHtE/KtZdbf2JmlQ/funmTym0UuNxh5yAFwEHFFdH8kbETFb0nBJi1fuHgqcB/wSeABYCXgfsChwqKRF+/Fp2ACS3z8CkDS4q7KSfinpE325f4dGL+UgeLO5ls8CM4HxEXFgtWwOisMkPQg8CpwhaRtJQyPiFeBiYFngrxExJSImAScC6wNr5W14cHQB1uAE1CHpB5IurATFj4Hf5/faG3ndIEljJI2obSf//R7g7bVt9UUdHRq9JGnhnOb7QDoL5H9flvQOSUtUin8Y+DhwArArqavyK+CD+f47gOeA6hvnRmAksE6/PpE2kj8Ag9+KAdngBDQL+CtwaKXYK8AKwN6STpB0EPAp4Apgz8p2VgICeDCv65OxDYdGofruSERMBf4HWE/SarklsWZuNt4OHJIf1wEcADwUET+LiFuBvYE7gS/mzV0JLAysXNnlbcCr5JbGW2EwNCJm525cvNWCQ9IOkraFuU5AN+ZW50hJw4HNSC2I44E1SWNfZwG/AY6WtFje3Euk982tfVlHh0Y35DPfm9OhtQ9uXr80MAP4AvBP4MvA8rnZeAGwZd7M6sAo4O+VTb8I/BHYWNLgiLgJeA1Yp9ZXzd2WB4DVJa3Uz0+1KXLudtQ3lzXHOEm/k/QP4DuSNqrd35IKN4mkIaT30bfy8hL5RLSQpHOAYyLiNdL76l7gxIh4b0RcFBEvAUcBU4EjJC0CrAhMJp2I+uz4OTS6IZ/5akGxhaSPS1o7nwlWBR4mpfpHI2K5iLgiP/RqYHNJg4BJwGDS2WJY3m4AjwOvk8YtILU81gaWqlThPmDpfBvwcu7OqjWX88Bx7XhsA/wCmAWcDmwA/FHSmgtSK6vR+EJEvE56n2wkaTLwDPCxiHgVmA6sKmlURPwauAdYQ9KyeXuD8/vxy8C2wB6kE9XTwMt5+31z/CLiLXEjBaQ6uU+kD/Sg6rr87whgF9K4w0mkMYe7gYeALXKZocB/SF0RVbaxLjAT2DovnwVcCqxQKfNF4H5g/bz8pbyPLSplRgIdrT6GPTjegzu5bzngK8B1pGDdPa9fHLgL+EKl7BDgEeD3wNBWP69+OE4rAwvnv5fJ76PZwDeARSvlDgX+AWyZl78K3FR5b3VUyh5C6hr/Dri/9nr0VZ3fMi2NqLQWIHUtKvdFzJkKXUzS8pWyiwA/A/6P9GFehXQ9xSvAZyUtFmm25N+ks2KtPwnpDfAg8IG8/HtgNHCqpHUkbUIKo6si4q5c5gzgE1T6oRExLfr4Ap3+kLtrg2DOuESDMksBZ5MGgq8iTTFPzXcvQjq+d0k6XNJE0tl2ECmoh/b/s+iZatO/MpA7z+dL0jKSRkv6sqTnSIPfp0laPyKeJrU47weIiCm1VhgpTGcBm+TlG4HhpDGNeicCtwD7kN6zRF9e19HqpO3nFK+e9d9JGj/Yrv5+0tnsq6Rp0CeAa4FPk89swGmk8Yf1Ko/9XH5htsvLP8zLa1fKDCIFzm2VdeOAa0iB8mqu02qtPlY9ObZ0cfYCtgZOJnUxNq2sP4wUAIs2eMxmpBbcDOCS/JqsDwxp9fNtUNehpLGHv8yn3KC65X8BE4Gf5+e7Lan7+VfSbJpIA5q35PId+d+lSNf+nJaXh5MGzk+vbHtI5e9R+VieQCct7J7eBnRLIw+aNUrzxSXtGhGRB5eIiAeA7Un9wE0lHUc68ADjSRdS/Qh4F6kbcRiwf77/btIIdfVirDtIV2vWkv8yUiti3VqBSOl+PbBhbeo1IiYAuwE7RsRCEfGRiHikd0ei/zS4bqDWkoiY96rW5SRdJ+n9pG7XMGB54FJJ2+ViC5P62AdJ2k/STrnVNYQ0aPcEcEFE7BQRx0Rqgc2WtL6k1fr1ydbpbOBQc67FGQEsXxugrg1eS1pL0k9zS+kESTtWHv47YCPgvoi4KSKuInUntiGdlIIUBuvn8YtZkhQRz5JOaitKWjrSgOgVwLskXSbpVdKJDkkdkQbQ/0W6+jgafU56rNWJ3UepP6zyt4AD88GqrRtN6lI8Q+ovPg/cDKyc778eOLRSfiPSm3diXt6MNED5qUqZJYALgTNrZwRSH/16Uvg8SOqjjgaOA0a3+jgVHtPhwCJ166ott1VIzd/1yGMXpIB4jNSC2juvWxr4G/mMnJePycfnQuAGUoicke8/hNTS2It0dh1F6sKdB4xr0bGotUjnGhcjjXXdDuxVWbcaaZzmz8BnSIO6jwD75vu3I51s1q/bx0zgwPz3O4BpwPZ1ZQ4gzdDtmpdHkK79OTofI9XV4zZg/z4/Hq1+c/byxRyVX7RHSNOctfXb5jfiDaR+4BmkgaTL8kFfp1J2LKlbcQapjz0lB8b5wIdIITQih8HP616YH5P6livl5XVJF2tdQBrIWqjVx6jweG5PGuy9gzTIdh7wfdJ3aGpl3plDYEp+U95Nul5gSD5Wp5CmiKtBvg9pdmmZuv2tRJoW3IUU5kvn9afkULkF+C9phulH1Xo06Xisko/BbnXrlyOdhPbK9/8irx+RQ+LCuvKn5uewUL5NIwcNc7ofNwFnAiPy8nWkbuxWpAu3NiSNX1wE7DKfem9J6v427Ab2+ri0+o3ayxd1E1JXYhJwLOnMNCivm01qHWxYO3Ckrse/yUmd1y2RX9D7SX3UjWsvXN2+fk06e6xYWXdwfrE3b/Wx6OVx3Dl/qKeSBms/QRq8PRF4lhSYY3PZk4G/AIvl5a1J4fzNvPzJvJ1hzDlDL086u25b2eeoyt/fIQXQ6pV178wfyvX663l347i8jTRjcWRe7iCF6HRSS/UCUuv1yspzfTofv4NJJ6HngCdJJ6VlcpnrgFPz34Pyv4eTxiBWystbApfn1+UG8qxJJ/XsoNIKIl3QtTMwvF+OS6vfsD18MWsHZ3/gXNLVcX8CjsvrRwM/AB6sHdT871BS8/lrzD1FdTmpqVzfzdkXeG9ePiw/9n2VMvOEy0C8kQYb7yR9X6b+vq1IYw2nkgL2SdKX6IbnN+ZJpOtMagN56+Tlzeteq3uBH+S/PwD8NG/zPlLoj6+Wb4dbfg+cSRpjgdSSfA74eF5egzRoPglYN6+7kXTCup7UbdiSSkDmMoeTWlILV9atmx83rrJu8U7q1dLp95a/MD19MStvvnvy39uSmn0b5+UPk84Iy+blWr/7YtKU31KV7e1OaspdmbezeQ6d60gX10D60s9WdHLtwUC+kZrMVwA/y8vV61UG5Q/4qzlcZuQ3/BRSt/B3pG5c7TgvTuoCHl3dFmkU/5H89yqkcY0TSa2JUc14nj08Np8hdZOWJV1DM5G5u8K75+f7ybx8MnBXg+2szJzresbmgNi4rsw4GsxIkcK4ba7TGZCzJ5GPJCmd75G0SKRR6J8DX5e0Oqm5+xJpVgRSnxtSMIwhnSVq2zuf9IZ4IW/jYlI35XhSn5WImBwR10WDaw8GukhXHD4GvEPS8MizInnUfjbpQxPAjqTm+j2kgbY1I2LfiDgXeDo/9iVgAun3QKrOB26TNDIiHouIr0bEpyLirEgj/e3qelILdS3SSWgU6RqdmrtJ0/Hvysu/IR3HH0laVembze8hjXFtmGeJ7iS10KbUNpJnZCZEg+sponL1bDsYkKFRmQpbj3QNxMuSRpNe3N1JU0/TSGeFnQEiYnp+zCX53+9KOk1S7UKaK4CPkrofS0TEDhFxTv5AvRVcTerDrwtvTq3WjvMzpGb5cNJFRqsA0yNNOyJpBVL3rfY9m78D78wBUfvS1ZURsWdETGvS8+krj5BOPtuRAmR18lfNASLiYVK3ba38fG8hTTd/gDQ+NIk0FjYcmBARr0e6kPDT+bG17bTsR3VKDcjQqLQ0ZgA/lPQEqd+9NWnAaQfgY6Txjl2VvnW6paTtI+Ih0pTs06Qvh30T3jyrzoqI/zT56bSLW0hN5tp1J6q8kaeSPigTSa2vRYGbJR0q6XjSwOiO5KsPSQOECw3AgJhHPmk8TBpQf4A0MLyfpLcBSNqadCXrquTWRkScSOrmHgvskU9C+0bEPbXt5muM+uT3LZptwP7cn9IvWZ1DajafSnrT/yfSpeDfJk2x7gN8ltQXX4Y0Sv/TSqvDstxs/jPwVEQckJvLsyUtQxrT2JJ0tesUSWNIX4jalhQo5wJ/jvQzAQscSeNJ35X5IGm86/9I4xj3kbotD5KC408RcVkn2+ggne8GTIuiMwM2NAAkPQN8PiL+WLd+CKlf/QfSB2F2RDzZ/BoOLJKOIX1/5n2RrkRclzSD9B7gGxFxtaQhEfF6bpkN3DdPAUmrkILx9Ij4eW5dHEyapTsdOL9RN7bWjV7QjlOXvy/YzjTnF7EWysu1M6MifcV4i9bVbsC6gjQTco2k5Uits+uA70bE1fDm17cXuA/CfEzOt9pPGlxLmmqdS758+80BywX1GA3Y0CBdfXcH6Xr8NweSFtQXqknuJs2MvEjqkvw1Ima0tkqtlwd8d6lfXxuTqAVFO81w9KcB3T0xaya1+L8OaBcODTMrMiCnXM2sdRwaZlbEoWFmRRwaZlbEodEDSv+jlc2Hj1P3DaRj5dDomQHzAreYj1P3DZhj5dAwsyJtf53G4EUWiqFLLzb/gk30xpRpDF50ZKurMRe91H5fmHzjtWkMHt5exwlg8MszW12FecycPZ2hg0a0uhpzmT7rZWbOmj7PL7K3/WXkQ5dejDV+ckCrq9H2hp63+PwLGQBLXv1W/fWDMn9/+qyG6909MbMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK9L00JC0o6QHJT0s6WvN3r+Z9U5TQ0NSB/BL4H3AWsBektZqZh3MrHea3dLYFHg4Ih6NiJnA2cCuTa6DmfVCs0Pj7cDjleUn8rq5SDpI0kRJE9+YMq1plTOz+Wt2aKjBuphnRcTJETE2IsYOXnRkE6plZt3V7NB4Alihsrw88GST62BmvdDs0LgVWEPSKpKGAuOBvzS5DmbWC4ObubOIeEPS54C/AR3AbyPi3mbWwcx6p6mhARARlwCXNHu/ZtY3fEWomRVxaJhZEYeGmRVxaJhZEYeGmRVxaJhZEYeGmRVxaJhZEYeGmRVxaJhZEYeGmRVxaJhZEYeGmRVxaJhZEYeGmRVxaJhZEYeGmRVxaJhZEYeGmRVxaJhZEYeGmRVxaJhZEYeGmRVxaJhZEYeGmRVxaJhZEYeGmRVxaJhZEYeGmRVxaJhZEYeGmRUZ3OoKzM/sVzt49e7FW12NtrfIi7NaXYUB46mdV2x1FQaE188d2nC9WxpmVsShYWZFHBpmVsShYWZFHBpmVsShYWZFHBpmVsShYWZFHBpmVsShYWZFHBpmVsShYWZFHBpmVsShYWZFHBpmVsShYWZFHBpmVsShYWZFHBpmVsShYWZFHBpmVsShYWZFHBpmVsShYWZFHBpmVsShYWZFHBpmVsShYWZFHBpmVsShYWZFHBpmVsShYWZFHBpmVqSpoSHpt5KelXRPM/drZn2n2S2N04Adm7xPM+tDTQ2NiLgOeLGZ+zSzvtWWYxqSDpI0UdLEWdOmtbo6ZlbRlqERESdHxNiIGNsxcmSrq2NmFW0ZGmbWvhwaZlak2VOuZwE3AWMkPSHpgGbu38x6b3AzdxYRezVzf2bW99w9MbMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zK+LQMLMiDg0zKzK41RWYn6FPvcoqR97W6mq0vZg1q9VVGDCufcLvp+7Y9MbnGq53S8PMijg0zKyIQ8PMijg0zKyIQ8PMijg0zKyIQ8PMijg0zKyIQ8PMijg0zKyIQ8PMijg0zKyIQ8PMijg0zKyIQ8PMijg0zKyIQ8PMinQ7NCQNlXS7pO37s0Jm1t66HRoRMRNYBXij/6pjZu2utHtyBeCWhtlbWOkPC/8COEPSYOBC4CkgqgUi4tE+qpuZtaHS0Lg2/3sY8MVOynT0vDpm1u5KQ2P/fqmFmQ0YRaEREaf3V0XMbGDo0XUakgZJWkfS1pJG9nWlzKx9FYeGpM8CTwN3A1cDY/L6CyV9vm+rZ2btpig0JH0S+Blp5mRPQJW7rwf26LuqmVk7Km1pHAYcGxEHARfU3fcAudVhZguu0tBYBfhbJ/dNAxbrXXXMrN2VhsbzwMqd3DcGmNyr2phZ2ysNjYuA70hatbIuJC1Jutjrwj6rmZm1pdLQ+BYwA7gHuJJ0CfnPgfuBWcCRfVo7M2s7RaERES8AY4EfAkOAR0gXiB0PbBYRU7p6vKQVJF0j6X5J90r6Qg/rbWYtUnoZORExFTgq30q9AXwpIm6XtDBwm6QrIuK+HmzLzFqg9DqNoyWt1NOdRcRTEXF7/nsqqVvz9p5uz8yar3RM4/PAI5IukbSLpB7/XKCklYENgVt6ug0za77SD/0ywGeBpUkzJf+W9F1JRa0FSaOA84BDI+LlBvcfJGmipImvx2uFVTSz/lQ6EDotIk6KiI2BdwGXA18BHpN0gaQd57cNSUNIgXFmRJzfyX5OjoixETF2iIaXVNHM+lmPuxcRcWtEHEC6SvTvwK7AXyU9KumzjboukgT8Brg/In7S032bWev0ZkxiNUnHAPcCm5O+i7I3cBPwU+DEBg/bAvgYsI2kO/Ntp57Wwcyar2jKVVIHsBtwMPBe4BngV8BJEfFkLna2pOuBHwMHVR8fETcw9zdjzWyAKb1OYzIwGrgO2Au4ICIa/ZcGdwAL97JuZtaGSkPjT8AJEXF/V4Ui4hb8v7eZLZBKfyP0kP6qiJkNDMWXkQNIWhxYA5hnPjQiruttpcysfZUOhA4Hfsu8P/VX5f/3xGwBVjru8G1gHPBxUmh8DjgQuIH0jded+7JyZtZ+SkNjD9JvZpydl2+JiFMjYmvgLmC+V4Sa2cBWGhorAvdGxCzgdaD6f578FvhIX1XMzNpTaWi8AIzKfz8OrF+5b0lgRF9UyszaV+nsyc2kr7NfSvrS2VH5x3TeAL5EGtswswVYaWj8mNRFAfg+sDppjKOD9J2TT/dd1cysHZVe3DURmJj/ngrsIWkYMAzYFLgYWK+vK2lm7aNHF3dVRcQMYIakRYG1e18lM2tn/n6ImRVxaJhZEYeGmRWZ75hG3X/B2JVlelkXMxsAujMQ+jDpv1+cH3WznJkNYN0Jjf37vRZmNmDMNzQi4vRmVMTMBgYPhJpZEYeGmRVxaJhZEYeGmRVxaJhZEYeGmRVxaJhZEYeGmRVxaJhZEYeGmRVxaJhZEYeGmRXp9W+E9rcZyy/EQ1/ZqNXVaH+D/KsE3bXDcrNaXYUB4aF4oeF6tzTMrIhDw8yKODTMrIhDw8yKODTMrIhDw8yKODTMrIhDw8yKODTMrIhDw8yKODTMrIhDw8yKODTMrIhDw8yKODTMrIhDw8yKODTMrIhDw8yKODTMrIhDw8yKODTMrIhDw8yKODTMrIhDw8yKODTMrIhDw8yKODTMrIhDw8yKODTMrIhDw8yKODTMrIhDw8yKODTMrEhTQ0PScEn/kHSXpHslfa+Z+zez3hvc5P3NALaJiFckDQFukHRpRNzc5HqYWQ81NTQiIoBX8uKQfItm1sHMeqfpYxqSOiTdCTwLXBERtzQoc5CkiZImznplWrOraGZdaHpoRMSsiNgAWB7YVNI6DcqcHBFjI2Jsx6iRza6imXWhZbMnEfFfYAKwY6vqYGblmj17MlrSYvnvEcB2wAPNrIOZ9U6zZ0+WBU6X1EEKrHMi4uIm18HMeqHZsyd3Axs2c59m1rd8RaiZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFRnc6grMz/DJ0xnzjX+2uhptb9glo1pdhQHjuT3f3eoqDAizL7+54Xq3NMysiEPDzIo4NMysiEPDzIo4NMysiEPDzIo4NMysiEPDzIo4NMysiEPDzIo4NMysiEPDzIo4NMysiEPDzIo4NMysiEPDzIo4NMysiEPDzIo4NMysiEPDzIo4NMysiEPDzIo4NMysiEPDzIo4NMysiEPDzIo4NMysiEPDzIo4NMysiEPDzIo4NMysiEPDzIo4NMysSEtCQ1KHpDskXdyK/ZtZz7WqpfEF4P4W7dvMeqHpoSFpeeD9wCnN3reZ9V4rWho/Bb4KzG7Bvs2sl5oaGpJ2Bp6NiNvmU+4gSRMlTZwZrzWpdmbWHc1uaWwB7CJpEnA2sI2kM+oLRcTJETE2IsYO1fAmV9HMutLU0IiIr0fE8hGxMjAeuDoi9mlmHcysd3ydhpkVGdyqHUfEBGBCq/ZvZj3jloaZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRh4aZFXFomFkRRUSr69AlSc8B/251PeosCTzf6koMAD5O3deOx2qliBhdv7LtQ6MdSZoYEWNbXY925+PUfQPpWLl7YmZFHBpmVuQtHxqS9pMUldssSZMlnSNpTF3ZIyQFcHI/1OOIvP/BhY9bLD92o76uUx/o8+M0P5JOk/REH26vW6+LpHG53LjKugmSJsynzKGSdqcFx6qnit6gC7gPA08AHcBqwLeBqyStHRFTqgUjop1e4MWA75LqfnuL6zKXNjtO/e12YDPgvsIyhwI3RMQ+/Vi3PuXQmOPOiHg4/32jpCeBK4DNgUtbVy2TNCwiZrS6Hl2JiJeBm3tbZiB4y3dPuvBy/ndIV4UkLSLpeElPSpoh6UFJX5SkunKjJZ0g6fFc7nFJv5c0rItt7yjplbz9eV4rSSsDj+XFX1e6WPvlxzwjaUjdY0ZJmirph3m51mTeIzftX5L0sqQzJb2t7rGDJX1d0gP5OTwp6VhJw7s6RvmxIeloSd+U9ISk6ZKuk7RBXbkJkm6Q9AFJd0iaAXwm37eppCvzMZkm6SpJm3ayv80l3SrpNUmTJB1Sd/9oSSdJekjSq/n1+IOkt3fyFNaUdE0u+5SkI6uvSaOuR4M6zVVG0iRgJWDvymt3mqQP5b/Xb7CNCZJu6mwfTRERb+kbsB8QwBhSy2sYsCZwJfAMsEil7BHpkL25PAi4HpgGfAnYHvhZ3t4PKuUWB/4FvAB8EdgW2As4G1i4um1gcF7eF5gJfLuLug8DdqvtD3h3vo0G1srr96x7zMHAbGDVvDwul3scOBXYETgEmApcU/fYs/Nz/Q6wXS73X+C8bhzn2j5uBD4IfAR4MB+TJSrlJgDPksLwE7l+6+XbdOA24EPAHsCted36lcefRgr8x4HP5edzWt7/fpVyY/JrtQewFTA+b28SMLz+NQceAb6ZX+Nj87ojKuVqx3Fc3XOZ0FkZYEPgKeCyymu3Gul9OBk4oe4Yjql/Hi35zLT6Q9vqG3NCo/42GdikruwRzB0aOzd6EYFTgBnAknn5SGAWsGEX9ai9OQcDXwVeBw7sRv1Xzo+bp2x+015Vt+524LLKcu2NfFldub3z+m3z8nvy8r6dlNtgPvUM0sVLI+vq/jpwVF2dZ9dvDziXFFCLVdYtArwInF9Zd1re1/i6x19BukhQndSvA1ghP3a3Bq/L1+rK/5oUrIvVHcdxdc9lQoNjXS0zCTijk/fDlLrj9RPgJWBEKz8z7p7MsRuwCbAp6Ux4H3CJpDW7eMxWpDf4WXXrzwCGkga9IJ2dbo2IO7pRj+OA7wEfiohTul/9hk4A3itpDQBJm5DObic1KHtO3fKfSM+t9hx2JLV8zsvdlMF5RuHyfP9W3ajPJRExrbYQEZNIffzN6spNiog769ZtBVwcEf+tPP5l4C/A1nVlZwHn1a07G1gReLP7IenTku6S9ArwBvCffNcY5lV/fM4GRgHrNCjbF04GFiK1SMldwI8Dv4uI6f20z25xaMxxT0RMjIhbI+LPwC6ASInfmSWAF2PeQbqnK/cDvI00u9EdewH3krpHvXVBrsvBeflTwJPARQ3KPlNdiIiZpLNa7UO2FCkIXyG1Dmq3Z/P9c41/dOKZTtbVjyM81aDcEp2sf5rU/at6KSJe72TfbwfIYxwnkI7z7qSTxbtzmUZjNPV1n2t7fS0ingT+THrNIM3uLUHjwG8qz550IiKmS3qU1JfuzIvAEpKG5g9ZzTL53xfyv8/T/TfXtqSz96WSdoqIV0rqXRURr0s6BfiMpGNI/fZjIzzMTgQAAANnSURBVOKNBsWXri5IGkr6ME7Oq14AXiN1Uxp5shtVWrqTdZPr1jX6bsOLzDmuVcvk+6oWlzSkLjhq+67tazyp6/alWgFJq3RW8fz4R7vYXn84gTTtvzEp+K+PiK6mdJvCLY1OSFqINCj1XBfFriUdww/Xrd+b1JSvTa9dDmzaaDS8gXtJfd81gMskLTyf8rVWzohO7j8JWJTU3RhG6os3smfd8odJz602Un8Z6Qy8aG6R1d+6Exo7SRpZW8izP++u7KMr1wLvrx6P/PcH8n1VHaQBzqrxpO5H7UO+EKmlVLV/F/uvPz7jSa2ue+Zb867NoJPXLiKuBu4njWVsAZzYy331Cbc05thA0pKkLsmypJH3JYBfdPGYS4EbgBMljSZ94HcCDgR+GBG1by0eB3wUuFLS94F/kr7VuCvwqYiYWt1oRNyfp+WuIQXHjvVlKp4htQLGS7qbNLvxWES8kLc1WdJFpDGbiyLi8U62s7akU0l99XcARwPXRsRVeTsTJJ0FnCvpJ8A/SGMeK+fnfHhEPNTFsYI003G5pP8lBdj3SDMdx83ncQBHkQaer5L0Y1Jr5HDSh//IurJTgWPy6/kvUpdvO9KAda0VcxlwuKRv5OeyDWlWpjOfzFOstwI7kF7jI6pjLD10H/AeSTuTulrP57GemhNJszzPM+84TWu0chS2HW40nj15Frga2KGu7BFUZk/yukWA40n97ZnAQ6RpVdWVW4o0uFUr9zhwOjCsum3ylGtetwZpLOQmKlO/DZ5DbeD2dRrP5uyV17+/wWPH5ft2J808/Jf0ofsDefanUnYQ8AXgLlJXZUr++xhSC6Sr4xykIPpGfk6vkaar62dJJpCukGy0jXeRxiBeIYXjVcCmdWVOy9vfnPQBf400a/L5unIjgF+RWpJTgYuBVZh3KrX2uqxDCvHppA/3UcCgBsdxXN1zmTCfMu/Mx+HVfN9pdfVcNq//31Z/Vmo3fzX+LUDSmaTm7aoRMbvuvnGkD8P/RERfDL52VocAjo6Ib/XXPhZEkj5J6mK+I+ZcsdxS7p4swCS9G9iAdCHVYfWBYe1L0lqkMbXvARe2S2CAQ2NBdxOpKX86aSTeBo4TSF2sv5PG19qGuydmVsRTrmZWxKFhZkUcGmZWxKFhZkUcGmZWxKFhZkX+H+E+jCHm0zl0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.random.rand(5,3)\n",
    "x /= np.sum(x, axis=1, keepdims=True)\n",
    "fig = plt.figure(figsize=(2, 6))\n",
    "# ax = fig.add_subplot(1, 1, 1)\n",
    "# # plot the attention weights\n",
    "# ax.matshow(x, cmap='viridis')\n",
    "# fontdict = {'fontsize': 20}\n",
    "# ax.set_xticks(range(x.shape[1]))\n",
    "# ax.set_yticks(range(x.shape[0]))\n",
    "# ax.set_xticklabels(['Attn', 'FFN', 'Id'], fontdict=fontdict, rotation=45)\n",
    "# ax.set_yticklabels([i for i in range(x.shape[1])], fontdict=fontdict)\n",
    "# ax.set_xlabel(f'Block type probability {1}')\n",
    "# ax.set_ylabel(f'Layer')\n",
    "# plot the attention weights\n",
    "plt.matshow(x, cmap='viridis')\n",
    "fontdict = {'fontsize': 20}\n",
    "plt.xticks(range(x.shape[1]), ['Attention', 'Dense', 'Identity'], rotation=15, size=14)\n",
    "plt.yticks(range(x.shape[0]), range(x.shape[0]))\n",
    "plt.xlabel(f'Block type probability', size=16)\n",
    "plt.ylabel(f'Layer', size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None]\n",
      "[None, None, 5, None]\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def train_step(inp, x_mems, labels, tau):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss, mems = model(x, x_mems=x_mems, labels=labels, training=True, tau=tau)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_perp(tf.math.exp(loss))\n",
    "    return mems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, mems, labels):\n",
    "    loss, mems = model(inp, mems, labels, 2.0, True, None)\n",
    "    return mems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_dm.get_inp_tar_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, lbl = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = model(inp, None, lbl, 2.0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction train_step(inp, mems=None, labels) at 0x7FBB6D8579A0>"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_step.get_concrete_function(inp, None, lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=int64, numpy=0>\n",
      "<tf.Variable 'Variable:0' shape=() dtype=int64, numpy=1>\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(0, dtype=tf.int64)\n",
    "print(x)\n",
    "x.assign_add(1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train_step(inp, inp, labels=lbl, tau=2.0)\n",
    "print(train_step.pretty_printed_concrete_signatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on PARTransformerXL in module par_model object:\n",
      "\n",
      "class PARTransformerXL(tensorflow.python.keras.engine.training.Model)\n",
      " |  PARTransformerXL(*args, **kwargs)\n",
      " |  \n",
      " |  `Model` groups layers into an object with training and inference features.\n",
      " |  \n",
      " |  Arguments:\n",
      " |      inputs: The input(s) of the model: a `keras.Input` object or list of\n",
      " |          `keras.Input` objects.\n",
      " |      outputs: The output(s) of the model. See Functional API example below.\n",
      " |      name: String, the name of the model.\n",
      " |  \n",
      " |  There are two ways to instantiate a `Model`:\n",
      " |  \n",
      " |  1 - With the \"Functional API\", where you start from `Input`,\n",
      " |  you chain layer calls to specify the model's forward pass,\n",
      " |  and finally you create your model from inputs and outputs:\n",
      " |  \n",
      " |  ```python\n",
      " |  import tensorflow as tf\n",
      " |  \n",
      " |  inputs = tf.keras.Input(shape=(3,))\n",
      " |  x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)\n",
      " |  outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)\n",
      " |  model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
      " |  ```\n",
      " |  \n",
      " |  2 - By subclassing the `Model` class: in that case, you should define your\n",
      " |  layers in `__init__` and you should implement the model's forward pass\n",
      " |  in `call`.\n",
      " |  \n",
      " |  ```python\n",
      " |  import tensorflow as tf\n",
      " |  \n",
      " |  class MyModel(tf.keras.Model):\n",
      " |  \n",
      " |    def __init__(self):\n",
      " |      super(MyModel, self).__init__()\n",
      " |      self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
      " |      self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\n",
      " |  \n",
      " |    def call(self, inputs):\n",
      " |      x = self.dense1(inputs)\n",
      " |      return self.dense2(x)\n",
      " |  \n",
      " |  model = MyModel()\n",
      " |  ```\n",
      " |  \n",
      " |  If you subclass `Model`, you can optionally have\n",
      " |  a `training` argument (boolean) in `call`, which you can use to specify\n",
      " |  a different behavior in training and inference:\n",
      " |  \n",
      " |  ```python\n",
      " |  import tensorflow as tf\n",
      " |  \n",
      " |  class MyModel(tf.keras.Model):\n",
      " |  \n",
      " |    def __init__(self):\n",
      " |      super(MyModel, self).__init__()\n",
      " |      self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
      " |      self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\n",
      " |      self.dropout = tf.keras.layers.Dropout(0.5)\n",
      " |  \n",
      " |    def call(self, inputs, training=False):\n",
      " |      x = self.dense1(inputs)\n",
      " |      if training:\n",
      " |        x = self.dropout(x, training=training)\n",
      " |      return self.dense2(x)\n",
      " |  \n",
      " |  model = MyModel()\n",
      " |  ```\n",
      " |  \n",
      " |  Once the model is created, you can config the model with losses and metrics\n",
      " |  with `model.compile()`, train the model with `model.fit()`, or use the model\n",
      " |  to do prediction with `model.predict()`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      PARTransformerXL\n",
      " |      tensorflow.python.keras.engine.training.Model\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      tensorflow.python.keras.utils.version_utils.LayerVersionSelector\n",
      " |      tensorflow.python.keras.utils.version_utils.ModelVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, d_model, num_heads, max_position, d_ffn, num_layers, mem_len, vocab_size, dropout_rate=0.1, cutoffs=None, proj_factor=4, proj_dims=None, **kwargs)\n",
      " |  \n",
      " |  call(self, x, x_mems=None, tau=None, labels=None, training=None, pad_mask=None)\n",
      " |      Calls the model on new inputs.\n",
      " |      \n",
      " |      In this case `call` just reapplies\n",
      " |      all ops in the graph to the new inputs\n",
      " |      (e.g. build a new computational graph from the provided inputs).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: A tensor or list of tensors.\n",
      " |          training: Boolean or boolean scalar tensor, indicating whether to run\n",
      " |            the `Network` in training mode or inference mode.\n",
      " |          mask: A mask or list of masks. A mask can be\n",
      " |              either a tensor or None (no mask).\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor if there is a single output, or\n",
      " |          a list of tensors if there are more than one outputs.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Builds the model based on input shapes received.\n",
      " |      \n",
      " |      This is to be used for subclassed models, which do not know at instantiation\n",
      " |      time what their inputs look like.\n",
      " |      \n",
      " |      This method only exists for users who want to call `model.build()` in a\n",
      " |      standalone way (as a substitute for calling the model on real data to\n",
      " |      build it). It will never be called by the framework (and thus it will\n",
      " |      never throw unexpected errors in an unrelated workflow).\n",
      " |      \n",
      " |      Args:\n",
      " |       input_shape: Single tuple, TensorShape, or list/dict of shapes, where\n",
      " |           shapes are tuples, integers, or TensorShapes.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError:\n",
      " |          1. In case of invalid user-provided data (not of type tuple,\n",
      " |             list, TensorShape, or dict).\n",
      " |          2. If the model requires call arguments that are agnostic\n",
      " |             to the input shapes (positional or kwarg in call signature).\n",
      " |          3. If not all layers were properly built.\n",
      " |          4. If float type inputs are not supported within the layers.\n",
      " |      \n",
      " |        In each of these cases, the user should build their model by calling it\n",
      " |        on real tensor data.\n",
      " |  \n",
      " |  compile(self, optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, weighted_metrics=None, run_eagerly=None, steps_per_execution=None, **kwargs)\n",
      " |      Configures the model for training.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          optimizer: String (name of optimizer) or optimizer instance. See\n",
      " |            `tf.keras.optimizers`.\n",
      " |          loss: String (name of objective function), objective function or\n",
      " |            `tf.keras.losses.Loss` instance. See `tf.keras.losses`. An objective\n",
      " |            function is any callable with the signature `loss = fn(y_true,\n",
      " |            y_pred)`, where y_true = ground truth values with shape =\n",
      " |            `[batch_size, d0, .. dN]`, except sparse loss functions such as sparse\n",
      " |            categorical crossentropy where shape = `[batch_size, d0, .. dN-1]`.\n",
      " |            y_pred = predicted values with shape = `[batch_size, d0, .. dN]`. It\n",
      " |            returns a weighted loss float tensor. If a custom `Loss` instance is\n",
      " |            used and reduction is set to NONE, return value has the shape\n",
      " |            [batch_size, d0, .. dN-1] ie. per-sample or per-timestep loss values;\n",
      " |            otherwise, it is a scalar. If the model has multiple outputs, you can\n",
      " |            use a different loss on each output by passing a dictionary or a list\n",
      " |            of losses. The loss value that will be minimized by the model will\n",
      " |            then be the sum of all individual losses.\n",
      " |          metrics: List of metrics to be evaluated by the model during training\n",
      " |            and testing. Each of this can be a string (name of a built-in\n",
      " |            function), function or a `tf.keras.metrics.Metric` instance. See\n",
      " |            `tf.keras.metrics`. Typically you will use `metrics=['accuracy']`. A\n",
      " |            function is any callable with the signature `result = fn(y_true,\n",
      " |            y_pred)`. To specify different metrics for different outputs of a\n",
      " |            multi-output model, you could also pass a dictionary, such as\n",
      " |              `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
      " |                You can also pass a list (len = len(outputs)) of lists of metrics\n",
      " |                such as `metrics=[['accuracy'], ['accuracy', 'mse']]` or\n",
      " |                `metrics=['accuracy', ['accuracy', 'mse']]`. When you pass the\n",
      " |                strings 'accuracy' or 'acc', we convert this to one of\n",
      " |                `tf.keras.metrics.BinaryAccuracy`,\n",
      " |                `tf.keras.metrics.CategoricalAccuracy`,\n",
      " |                `tf.keras.metrics.SparseCategoricalAccuracy` based on the loss\n",
      " |                function used and the model output shape. We do a similar\n",
      " |                conversion for the strings 'crossentropy' and 'ce' as well.\n",
      " |          loss_weights: Optional list or dictionary specifying scalar coefficients\n",
      " |            (Python floats) to weight the loss contributions of different model\n",
      " |            outputs. The loss value that will be minimized by the model will then\n",
      " |            be the *weighted sum* of all individual losses, weighted by the\n",
      " |            `loss_weights` coefficients.\n",
      " |              If a list, it is expected to have a 1:1 mapping to the model's\n",
      " |                outputs. If a dict, it is expected to map output names (strings)\n",
      " |                to scalar coefficients.\n",
      " |          weighted_metrics: List of metrics to be evaluated and weighted by\n",
      " |            sample_weight or class_weight during training and testing.\n",
      " |          run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`'s\n",
      " |            logic will not be wrapped in a `tf.function`. Recommended to leave\n",
      " |            this as `None` unless your `Model` cannot be run inside a\n",
      " |            `tf.function`.\n",
      " |          steps_per_execution: Int. Defaults to 1. The number of batches to\n",
      " |            run during each `tf.function` call. Running multiple batches\n",
      " |            inside a single `tf.function` call can greatly improve performance\n",
      " |            on TPUs or small models with a large Python overhead.\n",
      " |            At most, one full epoch will be run each\n",
      " |            execution. If a number larger than the size of the epoch is passed,\n",
      " |            the execution will be truncated to the size of the epoch.\n",
      " |            Note that if `steps_per_execution` is set to `N`,\n",
      " |            `Callback.on_batch_begin` and `Callback.on_batch_end` methods\n",
      " |            will only be called every `N` batches\n",
      " |            (i.e. before/after each `tf.function` execution).\n",
      " |          **kwargs: Arguments supported for backwards compatibility only.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid arguments for\n",
      " |              `optimizer`, `loss` or `metrics`.\n",
      " |  \n",
      " |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False)\n",
      " |      Returns the loss value & metrics values for the model in test mode.\n",
      " |      \n",
      " |      Computation is done in batches (see the `batch_size` arg.)\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset. Should return a tuple\n",
      " |              of either `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      " |              or `(inputs, targets, sample_weights)`.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
      " |            for iterator-like inputs` section of `Model.fit`.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
      " |            `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`\n",
      " |            should not be specified (since targets will be obtained from the\n",
      " |            iterator/dataset).\n",
      " |          batch_size: Integer or `None`. Number of samples per batch of\n",
      " |            computation. If unspecified, `batch_size` will default to 32. Do not\n",
      " |            specify the `batch_size` if your data is in the form of a dataset,\n",
      " |            generators, or `keras.utils.Sequence` instances (since they generate\n",
      " |            batches).\n",
      " |          verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\n",
      " |          sample_weight: Optional Numpy array of weights for the test samples,\n",
      " |            used for weighting the loss function. You can either pass a flat (1D)\n",
      " |            Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples), or in the case of\n",
      " |                temporal data, you can pass a 2D array with shape `(samples,\n",
      " |                sequence_length)`, to apply a different weight to every timestep\n",
      " |                of every sample. This argument is not supported when `x` is a\n",
      " |                dataset, instead pass sample weights as the third element of `x`.\n",
      " |          steps: Integer or `None`. Total number of steps (batches of samples)\n",
      " |            before declaring the evaluation round finished. Ignored with the\n",
      " |            default value of `None`. If x is a `tf.data` dataset and `steps` is\n",
      " |            None, 'evaluate' will run until the dataset is exhausted. This\n",
      " |            argument is not supported with array inputs.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances. List of\n",
      " |            callbacks to apply during evaluation. See\n",
      " |            [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |            input only. Maximum size for the generator queue. If unspecified,\n",
      " |            `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |            only. Maximum number of processes to spin up when using process-based\n",
      " |            threading. If unspecified, `workers` will default to 1. If 0, will\n",
      " |            execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |            `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |            threading. If unspecified, `use_multiprocessing` will default to\n",
      " |            `False`. Note that because this implementation relies on\n",
      " |            multiprocessing, you should not pass non-picklable arguments to the\n",
      " |            generator as they can't be passed easily to children processes.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.evaluate` is wrapped in `tf.function`.\n",
      " |          ValueError: in case of invalid arguments.\n",
      " |  \n",
      " |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Evaluates the model on a data generator.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.evaluate` now supports generators, so there is no longer any need\n",
      " |        to use this endpoint.\n",
      " |  \n",
      " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset. Should return a tuple\n",
      " |              of either `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      " |              or `(inputs, targets, sample_weights)`.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given below.\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      " |            tensor targets, or inversely). If `x` is a dataset, generator,\n",
      " |            or `keras.utils.Sequence` instance, `y` should\n",
      " |            not be specified (since targets will be obtained from `x`).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire `x` and `y`\n",
      " |              data provided.\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |              Note that the progress bar is not particularly useful when\n",
      " |              logged to a file, so verbose=2 is recommended when not running\n",
      " |              interactively (eg, in a production environment).\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See `tf.keras.callbacks`. Note `tf.keras.callbacks.ProgbarLogger`\n",
      " |              and `tf.keras.callbacks.History` callbacks are created automatically\n",
      " |              and need not be passed into `model.fit`.\n",
      " |              `tf.keras.callbacks.ProgbarLogger` is created or not based on\n",
      " |              `verbose` argument to `model.fit`.\n",
      " |          validation_split: Float between 0 and 1.\n",
      " |              Fraction of the training data to be used as validation data.\n",
      " |              The model will set apart this fraction of the training data,\n",
      " |              will not train on it, and will evaluate\n",
      " |              the loss and any model metrics\n",
      " |              on this data at the end of each epoch.\n",
      " |              The validation data is selected from the last samples\n",
      " |              in the `x` and `y` data provided, before shuffling. This argument is\n",
      " |              not supported when `x` is a dataset, generator or\n",
      " |             `keras.utils.Sequence` instance.\n",
      " |          validation_data: Data on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data. Thus, note the fact\n",
      " |              that the validation loss of data provided using `validation_split`\n",
      " |              or `validation_data` is not affected by regularization layers like\n",
      " |              noise and dropout.\n",
      " |              `validation_data` will override `validation_split`.\n",
      " |              `validation_data` could be:\n",
      " |                - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
      " |                - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
      " |                - dataset\n",
      " |              For the first two cases, `batch_size` must be provided.\n",
      " |              For the last case, `validation_steps` could be provided.\n",
      " |              Note that `validation_data` does not support all the data types that\n",
      " |              are supported in `x`, eg, dict, generator or `keras.utils.Sequence`.\n",
      " |          shuffle: Boolean (whether to shuffle the training data\n",
      " |              before each epoch) or str (for 'batch'). This argument is ignored\n",
      " |              when `x` is a generator. 'batch' is a special option for dealing\n",
      " |              with the limitations of HDF5 data; it shuffles in batch-sized\n",
      " |              chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only).\n",
      " |              This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from\n",
      " |              an under-represented class.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the training samples, used for weighting the loss function\n",
      " |              (during training only). You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample. This\n",
      " |              argument is not supported when `x` is a dataset, generator, or\n",
      " |             `keras.utils.Sequence` instance, instead provide the sample_weights\n",
      " |              as the third element of `x`.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |          steps_per_epoch: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring one epoch finished and starting the\n",
      " |              next epoch. When training with input tensors such as\n",
      " |              TensorFlow data tensors, the default `None` is equal to\n",
      " |              the number of samples in your dataset divided by\n",
      " |              the batch size, or 1 if that cannot be determined. If x is a\n",
      " |              `tf.data` dataset, and 'steps_per_epoch'\n",
      " |              is None, the epoch will run until the input dataset is exhausted.\n",
      " |              When passing an infinitely repeating dataset, you must specify the\n",
      " |              `steps_per_epoch` argument. This argument is not supported with\n",
      " |              array inputs.\n",
      " |          validation_steps: Only relevant if `validation_data` is provided and\n",
      " |              is a `tf.data` dataset. Total number of steps (batches of\n",
      " |              samples) to draw before stopping when performing validation\n",
      " |              at the end of every epoch. If 'validation_steps' is None, validation\n",
      " |              will run until the `validation_data` dataset is exhausted. In the\n",
      " |              case of an infinitely repeated dataset, it will run into an\n",
      " |              infinite loop. If 'validation_steps' is specified and only part of\n",
      " |              the dataset will be consumed, the evaluation will start from the\n",
      " |              beginning of the dataset at each epoch. This ensures that the same\n",
      " |              validation samples are used every time.\n",
      " |          validation_batch_size: Integer or `None`.\n",
      " |              Number of samples per validation batch.\n",
      " |              If unspecified, will default to `batch_size`.\n",
      " |              Do not specify the `validation_batch_size` if your data is in the\n",
      " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          validation_freq: Only relevant if validation data is provided. Integer\n",
      " |              or `collections_abc.Container` instance (e.g. list, tuple, etc.).\n",
      " |              If an integer, specifies how many training epochs to run before a\n",
      " |              new validation run is performed, e.g. `validation_freq=2` runs\n",
      " |              validation every 2 epochs. If a Container, specifies the epochs on\n",
      " |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
      " |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up\n",
      " |              when using process-based threading. If unspecified, `workers`\n",
      " |              will default to 1. If 0, will execute the generator on the main\n",
      " |              thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      Unpacking behavior for iterator-like inputs:\n",
      " |          A common pattern is to pass a tf.data.Dataset, generator, or\n",
      " |        tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
      " |        yield not only features (x) but optionally targets (y) and sample weights.\n",
      " |        Keras requires that the output of such iterator-likes be unambiguous. The\n",
      " |        iterator should return a tuple of length 1, 2, or 3, where the optional\n",
      " |        second and third elements will be used for y and sample_weight\n",
      " |        respectively. Any other type provided will be wrapped in a length one\n",
      " |        tuple, effectively treating everything as 'x'. When yielding dicts, they\n",
      " |        should still adhere to the top-level tuple structure.\n",
      " |        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
      " |        features, targets, and weights from the keys of a single dict.\n",
      " |          A notable unsupported data type is the namedtuple. The reason is that\n",
      " |        it behaves like both an ordered datatype (tuple) and a mapping\n",
      " |        datatype (dict). So given a namedtuple of the form:\n",
      " |            `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
      " |        it is ambiguous whether to reverse the order of the elements when\n",
      " |        interpreting the value. Even worse is a tuple of the form:\n",
      " |            `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
      " |        where it is unclear if the tuple was intended to be unpacked into x, y,\n",
      " |        and sample_weight or passed through as a single element to `x`. As a\n",
      " |        result the data processing code will simply raise a ValueError if it\n",
      " |        encounters a namedtuple. (Along with instructions to remedy the issue.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: 1. If the model was never compiled or,\n",
      " |          2. If `model.fit` is  wrapped in `tf.function`.\n",
      " |      \n",
      " |          ValueError: In case of mismatch between the provided input data\n",
      " |              and what the model expects or when the input data is empty.\n",
      " |  \n",
      " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
      " |      Fits the model on data yielded batch-by-batch by a Python generator.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.fit` now supports generators, so there is no longer any need to use\n",
      " |        this endpoint.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      If `name` and `index` are both provided, `index` will take precedence.\n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid layer name or index.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Retrieves the weights of the model.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A flat list of Numpy arrays.\n",
      " |  \n",
      " |  load_weights(self, filepath, by_name=False, skip_mismatch=False, options=None)\n",
      " |      Loads all layer weights, either from a TensorFlow or an HDF5 weight file.\n",
      " |      \n",
      " |      If `by_name` is False weights are loaded based on the network's\n",
      " |      topology. This means the architecture should be the same as when the weights\n",
      " |      were saved.  Note that layers that don't have weights are not taken into\n",
      " |      account in the topological ordering, so adding or removing layers is fine as\n",
      " |      long as they don't have weights.\n",
      " |      \n",
      " |      If `by_name` is True, weights are loaded into layers only if they share the\n",
      " |      same name. This is useful for fine-tuning or transfer-learning models where\n",
      " |      some of the layers have changed.\n",
      " |      \n",
      " |      Only topological loading (`by_name=False`) is supported when loading weights\n",
      " |      from the TensorFlow format. Note that topological loading differs slightly\n",
      " |      between TensorFlow and HDF5 formats for user-defined classes inheriting from\n",
      " |      `tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the\n",
      " |      TensorFlow format loads based on the object-local names of attributes to\n",
      " |      which layers are assigned in the `Model`'s constructor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String, path to the weights file to load. For weight files in\n",
      " |              TensorFlow format, this is the file prefix (the same as was passed\n",
      " |              to `save_weights`).\n",
      " |          by_name: Boolean, whether to load weights by name or by topological\n",
      " |              order. Only topological loading is supported for weight files in\n",
      " |              TensorFlow format.\n",
      " |          skip_mismatch: Boolean, whether to skip loading of layers where there is\n",
      " |              a mismatch in the number of weights, or a mismatch in the shape of\n",
      " |              the weight (only valid when `by_name=True`).\n",
      " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
      " |              options for loading weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          When loading a weight file in TensorFlow format, returns the same status\n",
      " |          object as `tf.train.Checkpoint.restore`. When graph building, restore\n",
      " |          ops are run automatically as soon as the network is built (on first call\n",
      " |          for user-defined classes inheriting from `Model`, immediately if it is\n",
      " |          already built).\n",
      " |      \n",
      " |          When loading weights in HDF5 format, returns `None`.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If h5py is not available and the weight file is in HDF5\n",
      " |              format.\n",
      " |          ValueError: If `skip_mismatch` is set to `True` when `by_name` is\n",
      " |            `False`.\n",
      " |  \n",
      " |  make_predict_function(self)\n",
      " |      Creates a function that executes one step of inference.\n",
      " |      \n",
      " |      This method can be overridden to support custom inference logic.\n",
      " |      This method is called by `Model.predict` and `Model.predict_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
      " |      logic to `Model.predict_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.predict` or\n",
      " |      `Model.predict_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return the outputs of the `Model`.\n",
      " |  \n",
      " |  make_test_function(self)\n",
      " |      Creates a function that executes one step of evaluation.\n",
      " |      \n",
      " |      This method can be overridden to support custom evaluation logic.\n",
      " |      This method is called by `Model.evaluate` and `Model.test_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
      " |      logic to `Model.test_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.evaluate` or\n",
      " |      `Model.test_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
      " |        be passed to `tf.keras.Callbacks.on_test_batch_end`.\n",
      " |  \n",
      " |  make_train_function(self)\n",
      " |      Creates a function that executes one step of training.\n",
      " |      \n",
      " |      This method can be overridden to support custom training logic.\n",
      " |      This method is called by `Model.fit` and `Model.train_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual training\n",
      " |      logic to `Model.train_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.fit` or\n",
      " |      `Model.train_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
      " |        be passed to `tf.keras.Callbacks.on_train_batch_end`, such as\n",
      " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Generates output predictions for the input samples.\n",
      " |      \n",
      " |      Computation is done in batches. This method is designed for performance in\n",
      " |      large scale inputs. For small amount of inputs that fit in one batch,\n",
      " |      directly using `__call__` is recommended for faster execution, e.g.,\n",
      " |      `model(x)`, or `model(x, training=False)` if you have layers such as\n",
      " |      `tf.keras.layers.BatchNormalization` that behaves differently during\n",
      " |      inference. Also, note the fact that test loss is not affected by\n",
      " |      regularization layers like noise and dropout.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input samples. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A `tf.data` dataset.\n",
      " |            - A generator or `keras.utils.Sequence` instance.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
      " |            for iterator-like inputs` section of `Model.fit`.\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per batch.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of dataset, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          verbose: Verbosity mode, 0 or 1.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              before declaring the prediction round finished.\n",
      " |              Ignored with the default value of `None`. If x is a `tf.data`\n",
      " |              dataset and `steps` is None, `predict` will\n",
      " |              run until the input dataset is exhausted.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during prediction.\n",
      " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up when using\n",
      " |              process-based threading. If unspecified, `workers` will default\n",
      " |              to 1. If 0, will execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`. Note that Model.predict uses the same interpretation rules as\n",
      " |      `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all\n",
      " |      three methods.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.predict` is wrapped in `tf.function`.\n",
      " |          ValueError: In case of mismatch between the provided\n",
      " |              input data and the model's expectations,\n",
      " |              or in case a stateful model receives a number of samples\n",
      " |              that is not a multiple of the batch size.\n",
      " |  \n",
      " |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Generates predictions for the input samples from a data generator.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.predict` now supports generators, so there is no longer any need\n",
      " |        to use this endpoint.\n",
      " |  \n",
      " |  predict_on_batch(self, x)\n",
      " |      Returns predictions for a single batch of samples.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
      " |            of arrays (in case the model has multiple inputs). - A TensorFlow\n",
      " |            tensor, or a list of tensors (in case the model has multiple inputs).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.predict_on_batch` is wrapped in `tf.function`.\n",
      " |          ValueError: In case of mismatch between given number of inputs and\n",
      " |            expectations of the model.\n",
      " |  \n",
      " |  predict_step(self, data)\n",
      " |      The logic for one inference step.\n",
      " |      \n",
      " |      This method can be overridden to support custom inference logic.\n",
      " |      This method is called by `Model.make_predict_function`.\n",
      " |      \n",
      " |      This method should contain the mathematical logic for one step of inference.\n",
      " |      This typically includes the forward pass.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_predict_function`, which can also be overridden.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The result of one inference step, typically the output of calling the\n",
      " |        `Model` on data.\n",
      " |  \n",
      " |  reset_metrics(self)\n",
      " |      Resets the state of all the metrics in the model.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> _ = model.fit(x, y, verbose=0)\n",
      " |      >>> assert all(float(m.result()) for m in model.metrics)\n",
      " |      \n",
      " |      >>> model.reset_metrics()\n",
      " |      >>> assert all(float(m.result()) == 0 for m in model.metrics)\n",
      " |  \n",
      " |  reset_states(self)\n",
      " |  \n",
      " |  save(self, filepath, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None, save_traces=True)\n",
      " |      Saves the model to Tensorflow SavedModel or a single HDF5 file.\n",
      " |      \n",
      " |      Please see `tf.keras.models.save_model` or the\n",
      " |      [Serialization and Saving guide](https://keras.io/guides/serialization_and_saving/)\n",
      " |      for details.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String, PathLike, path to SavedModel or H5 file to save the\n",
      " |              model.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          include_optimizer: If True, save optimizer's state together.\n",
      " |          save_format: Either `'tf'` or `'h5'`, indicating whether to save the\n",
      " |              model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X,\n",
      " |              and 'h5' in TF 1.X.\n",
      " |          signatures: Signatures to save with the SavedModel. Applicable to the\n",
      " |              'tf' format only. Please see the `signatures` argument in\n",
      " |              `tf.saved_model.save` for details.\n",
      " |          options: (only applies to SavedModel format)\n",
      " |              `tf.saved_model.SaveOptions` object that specifies options for\n",
      " |              saving to SavedModel.\n",
      " |          save_traces: (only applies to SavedModel format) When enabled, the\n",
      " |              SavedModel will store the function traces for each layer. This\n",
      " |              can be disabled, so that only the configs of each layer are stored.\n",
      " |              Defaults to `True`. Disabling this will decrease serialization time\n",
      " |              and reduce file size, but it requires that all custom layers/models\n",
      " |              implement a `get_config()` method.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      from keras.models import load_model\n",
      " |      \n",
      " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
      " |      del model  # deletes the existing model\n",
      " |      \n",
      " |      # returns a compiled model\n",
      " |      # identical to the previous one\n",
      " |      model = load_model('my_model.h5')\n",
      " |      ```\n",
      " |  \n",
      " |  save_weights(self, filepath, overwrite=True, save_format=None, options=None)\n",
      " |      Saves all layer weights.\n",
      " |      \n",
      " |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
      " |      argument.\n",
      " |      \n",
      " |      When saving in HDF5 format, the weight file has:\n",
      " |        - `layer_names` (attribute), a list of strings\n",
      " |            (ordered names of model layers).\n",
      " |        - For every layer, a `group` named `layer.name`\n",
      " |            - For every such layer group, a group attribute `weight_names`,\n",
      " |                a list of strings\n",
      " |                (ordered names of weights tensor of the layer).\n",
      " |            - For every weight in the layer, a dataset\n",
      " |                storing the weight value, named after the weight tensor.\n",
      " |      \n",
      " |      When saving in TensorFlow format, all objects referenced by the network are\n",
      " |      saved in the same format as `tf.train.Checkpoint`, including any `Layer`\n",
      " |      instances or `Optimizer` instances assigned to object attributes. For\n",
      " |      networks constructed from inputs and outputs using `tf.keras.Model(inputs,\n",
      " |      outputs)`, `Layer` instances used by the network are tracked/saved\n",
      " |      automatically. For user-defined classes which inherit from `tf.keras.Model`,\n",
      " |      `Layer` instances must be assigned to object attributes, typically in the\n",
      " |      constructor. See the documentation of `tf.train.Checkpoint` and\n",
      " |      `tf.keras.Model` for details.\n",
      " |      \n",
      " |      While the formats are the same, do not mix `save_weights` and\n",
      " |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be\n",
      " |      loaded using `Model.load_weights`. Checkpoints saved using\n",
      " |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
      " |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
      " |      `save_weights` for training checkpoints.\n",
      " |      \n",
      " |      The TensorFlow format matches objects and variables by starting at a root\n",
      " |      object, `self` for `save_weights`, and greedily matching attribute\n",
      " |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this\n",
      " |      is the `Checkpoint` even if the `Checkpoint` has a model attached. This\n",
      " |      means saving a `tf.keras.Model` using `save_weights` and loading into a\n",
      " |      `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match\n",
      " |      the `Model`'s variables. See the [guide to training\n",
      " |      checkpoints](https://www.tensorflow.org/guide/checkpoint) for details\n",
      " |      on the TensorFlow format.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String or PathLike, path to the file to save the weights to.\n",
      " |              When saving in TensorFlow format, this is the prefix used for\n",
      " |              checkpoint files (multiple files are generated). Note that the '.h5'\n",
      " |              suffix causes weights to be saved in HDF5 format.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
      " |              '.keras' will default to HDF5 if `save_format` is `None`. Otherwise\n",
      " |              `None` defaults to 'tf'.\n",
      " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
      " |              options for saving weights.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If h5py is not available when attempting to save in HDF5\n",
      " |              format.\n",
      " |          ValueError: For invalid/unknown format arguments.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          line_length: Total length of printed lines\n",
      " |              (e.g. set this to adapt the display to different\n",
      " |              terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements\n",
      " |              in each line. If not provided,\n",
      " |              defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use. Defaults to `print`.\n",
      " |              It will be called on each line of the summary.\n",
      " |              You can set it to a custom function\n",
      " |              in order to capture the string summary.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if `summary()` is called before the model is built.\n",
      " |  \n",
      " |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True, return_dict=False)\n",
      " |      Test the model on a single batch of samples.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
      " |            of arrays (in case the model has multiple inputs). - A TensorFlow\n",
      " |            tensor, or a list of tensors (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors, if\n",
      " |            the model has named inputs.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case of\n",
      " |            temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.test_on_batch` is wrapped in `tf.function`.\n",
      " |          ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  test_step(self, data)\n",
      " |      The logic for one evaluation step.\n",
      " |      \n",
      " |      This method can be overridden to support custom evaluation logic.\n",
      " |      This method is called by `Model.make_test_function`.\n",
      " |      \n",
      " |      This function should contain the mathematical logic for one step of\n",
      " |      evaluation.\n",
      " |      This typically includes the forward pass, loss calculation, and metrics\n",
      " |      updates.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_test_function`, which can also be overridden.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `dict` containing values that will be passed to\n",
      " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
      " |        values of the `Model`'s metrics are returned.\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a JSON save file, use\n",
      " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON string.\n",
      " |  \n",
      " |  to_yaml(self, **kwargs)\n",
      " |      Returns a yaml string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a yaml save file, use\n",
      " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
      " |      \n",
      " |      `custom_objects` should be a dictionary mapping\n",
      " |      the names of custom losses / layers / etc to the corresponding\n",
      " |      functions / classes.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `yaml.dump()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A YAML string.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: if yaml module is not found.\n",
      " |  \n",
      " |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True, return_dict=False)\n",
      " |      Runs a single gradient update on a single batch of data.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |                if the model has named inputs.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case of\n",
      " |            temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers) to a\n",
      " |            weight (float) to apply to the model's loss for the samples from this\n",
      " |            class during training. This can be useful to tell the model to \"pay\n",
      " |            more attention\" to samples from an under-represented class.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar training loss\n",
      " |          (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If `model.train_on_batch` is wrapped in `tf.function`.\n",
      " |        ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  train_step(self, data)\n",
      " |      The logic for one training step.\n",
      " |      \n",
      " |      This method can be overridden to support custom training logic.\n",
      " |      This method is called by `Model.make_train_function`.\n",
      " |      \n",
      " |      This method should contain the mathematical logic for one step of training.\n",
      " |      This typically includes the forward pass, loss calculation, backpropagation,\n",
      " |      and metric updates.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_train_function`, which can also be overridden.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `dict` containing values that will be passed to\n",
      " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
      " |        values of the `Model`'s metrics are returned. Example:\n",
      " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  from_config(config, custom_objects=None) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  distribute_strategy\n",
      " |      The `tf.distribute.Strategy` this model was created under.\n",
      " |  \n",
      " |  layers\n",
      " |  \n",
      " |  metrics\n",
      " |      Returns the model's metrics added using `compile`, `add_metric` APIs.\n",
      " |      \n",
      " |      Note: Metrics passed to `compile()` are available only after a `keras.Model`\n",
      " |      has been trained/evaluated on actual data.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      []\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> model.fit(x, y)\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      ['loss', 'mae']\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
      " |      >>> output_1 = d(inputs)\n",
      " |      >>> output_2 = d(inputs)\n",
      " |      >>> model = tf.keras.models.Model(\n",
      " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
      " |      >>> model.add_metric(\n",
      " |      ...    tf.reduce_sum(output_2), name='mean', aggregation='mean')\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
      " |      >>> model.fit(x, (y, y))\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
      " |      'out_1_acc', 'mean']\n",
      " |  \n",
      " |  metrics_names\n",
      " |      Returns the model's display labels for all outputs.\n",
      " |      \n",
      " |      Note: `metrics_names` are available only after a `keras.Model` has been\n",
      " |      trained/evaluated on actual data.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      >>> model.metrics_names\n",
      " |      []\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> model.fit(x, y)\n",
      " |      >>> model.metrics_names\n",
      " |      ['loss', 'mae']\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
      " |      >>> output_1 = d(inputs)\n",
      " |      >>> output_2 = d(inputs)\n",
      " |      >>> model = tf.keras.models.Model(\n",
      " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
      " |      >>> model.fit(x, (y, y))\n",
      " |      >>> model.metrics_names\n",
      " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
      " |      'out_1_acc']\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are expected\n",
      " |      to be updated manually in `call()`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  state_updates\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Returns the `updates` from all layers that are stateful.\n",
      " |      \n",
      " |      This is useful for separating training updates and\n",
      " |      state updates, e.g. when we need to update a layer's internal state\n",
      " |      during prediction.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  run_eagerly\n",
      " |      Settable attribute indicating whether the model should run eagerly.\n",
      " |      \n",
      " |      Running eagerly means that your model will be run step by step,\n",
      " |      like Python code. Your model might run slower, but it should become easier\n",
      " |      for you to debug it by stepping into individual layer calls.\n",
      " |      \n",
      " |      By default, we will attempt to compile your model to a static graph to\n",
      " |      deliver the best execution performance.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Boolean, whether the model should run eagerly.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        *args: Positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |            inputs - Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(x))\n",
      " |          self.add_metric(tf.reduce_sum(x), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This is\n",
      " |      because we cannot trace the metric result tensor back to the model's inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result of\n",
      " |          calling a `keras.Metric` instance, it will be aggregated by default\n",
      " |          using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The variable created.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a Dense layer returns a list of two values-- per-output\n",
      " |      weights and the bias value. These can be used to set the weights of another\n",
      " |      Dense layer:\n",
      " |      \n",
      " |      >>> a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b.set_weights(a.get_weights())\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  compute_dtype\n",
      " |      The dtype of the layer's computations.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
      " |      the weights.\n",
      " |      \n",
      " |      Layers automatically cast their inputs to the compute dtype, which causes\n",
      " |      computations and the output to be in the compute dtype as well. This is done\n",
      " |      by the base Layer class in `Layer.__call__`, so you do not have to insert\n",
      " |      these casts if implementing your own layer.\n",
      " |      \n",
      " |      Layers often perform certain internal computations in higher precision when\n",
      " |      `compute_dtype` is float16 or bfloat16 for numeric stability. The output\n",
      " |      will still typically be float16 or bfloat16 in such cases.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The layer's compute dtype.\n",
      " |  \n",
      " |  dtype\n",
      " |      The dtype of the layer weights.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
      " |      dtype of the layer's computations.\n",
      " |  \n",
      " |  dtype_policy\n",
      " |      The dtype policy associated with this layer.\n",
      " |      \n",
      " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> len(model.losses)\n",
      " |      0\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> len(model.losses)\n",
      " |      1\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variable_dtype\n",
      " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
      " |      the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
      " |      of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
      " |      error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x, x_mems=None, labels=None, tau=None, training=None, pad_mask=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_pi_weights(model):\n",
    "    weights = []\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'pi'):\n",
    "            weight = layer.pi\n",
    "            weight /= tf.reduce_sum(weight)\n",
    "            weights.append(layer.pi)\n",
    "    num_blocks = len(weights)\n",
    "    weights = tf.stack(weights, 0).numpy()\n",
    "\n",
    "    plt.matshow(weights, cmap='viridis')\n",
    "    plt.xticks(range(3), ['Attention', 'Dense', 'Identity'], rotation=15, size=14)\n",
    "    plt.yticks(range(num_blocks), range(1, num_blocks+1))\n",
    "    plt.xlabel(f'Block type probability', size=16)\n",
    "    plt.ylabel(f'Stochastic block', size=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights = np.random.rand(5,3)\n",
    "plt.matshow(weights, cmap='viridis')\n",
    "plt.xticks(range(3), ['Attention', 'Dense', 'Identity'], rotation=15, size=14)\n",
    "plt.yticks(range(5), range(1, 5+1))\n",
    "plt.xlabel(f'Block type probability', size=16)\n",
    "plt.ylabel(f'Stochastic block', size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for i in range(100):\n",
    "    time.sleep(0.01)\n",
    "    x = 5/np.sqrt(i+1)\n",
    "    diff = (time.time()-start)/(i+1)\n",
    "    printBar(i, 100, diff, x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
