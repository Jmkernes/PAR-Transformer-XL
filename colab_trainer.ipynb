{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "from data_utils import DataManager\n",
    "from utils import print_bar, visualize_pi_weights\n",
    "from par_model import PARTransformerXL\n",
    "from par_model import create_lookahead_mask, positional_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2827"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dm.ds_size.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'write'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-447-8570658c2d89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpprint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model parameters:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pprint.py\u001b[0m in \u001b[0;36mpprint\u001b[0;34m(object, stream, indent, width, depth, compact, sort_dicts)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         compact=compact, sort_dicts=sort_dicts)\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m def pformat(object, indent=1, width=80, depth=None, *,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pprint.py\u001b[0m in \u001b[0;36mpprint\u001b[0;34m(self, object)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pprint.py\u001b[0m in \u001b[0;36m_format\u001b[0;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobjid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0m_dispatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'write'"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(\"Model parameters:\\n\",config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the wikitext2 train, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer from wiki2_12k.model...\n",
      "Loading tfrecords from directory\n",
      "WARNING:tensorflow:AutoGraph could not transform <function load_tfrecord_ds_from_files.<locals>.<lambda> at 0x7fbbdb18e160> and will run it as-is.\n",
      "Cause: could not parse the source code of <function load_tfrecord_ds_from_files.<locals>.<lambda> at 0x7fbbdb18e160>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function load_tfrecord_ds_from_files.<locals>.<lambda> at 0x7fbbdb18e160> and will run it as-is.\n",
      "Cause: could not parse the source code of <function load_tfrecord_ds_from_files.<locals>.<lambda> at 0x7fbbdb18e160>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function load_tfrecord_ds_from_files.<locals>.<lambda> at 0x7fbbd9971940> and will run it as-is.\n",
      "Cause: could not parse the source code of <function load_tfrecord_ds_from_files.<locals>.<lambda> at 0x7fbbd9971940>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function load_tfrecord_ds_from_files.<locals>.<lambda> at 0x7fbbd9971940> and will run it as-is.\n",
      "Cause: could not parse the source code of <function load_tfrecord_ds_from_files.<locals>.<lambda> at 0x7fbbd9971940>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Loading tokenizer from wiki2_12k.model...\n",
      "Loading tfrecords from directory\n",
      "Loading tokenizer from wiki2_12k.model...\n",
      "Loading tfrecords from directory\n"
     ]
    }
   ],
   "source": [
    "config = {'tfrecords_directory':'data/wikitext2_bsz32_seqlen32_tfrecords_train',\n",
    "                'sp_model_prefix': 'wiki2_12k'}\n",
    "train_dm = DataManager.initialize_from_tfrecord(config)\n",
    "\n",
    "config['tfrecords_directory'] = 'data/wikitext2_bsz32_seqlen32_tfrecords_valid'\n",
    "valid_dm = DataManager.initialize_from_tfrecord(config)\n",
    "\n",
    "config['tfrecords_directory'] = 'data/wikitext2_bsz32_seqlen32_tfrecords_test'\n",
    "test_dm = DataManager.initialize_from_tfrecord(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=2827>"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dm.ds_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "config = {\n",
    "    'd_model':64, \n",
    "    'num_heads':4, \n",
    "    'max_position':512, \n",
    "    'd_ffn':128,\n",
    "    'num_layers':6, \n",
    "    'mem_len':32, \n",
    "    'vocab_size':12000,\n",
    "    'dropout_rate':0.1, \n",
    "    'cutoffs':[250, 2500, 12000], \n",
    "    'proj_factor':2, \n",
    "    'proj_dims':None,\n",
    "}\n",
    "\n",
    "ds_size = train_dm.ds_size\n",
    "max_position = config['max_position']\n",
    "pos_enc = positional_encoding(max_position, config['d_model'])\n",
    "lookahead_mask = create_lookahead_mask(max_position, max_position)\n",
    "model = PARTransformerXL(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"par_transformer_xl\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  768000    \n",
      "_________________________________________________________________\n",
      "adaptive_softmax (AdaptiveSo multiple                  255250    \n",
      "_________________________________________________________________\n",
      "stochastic_block (Stochastic multiple                  37764     \n",
      "_________________________________________________________________\n",
      "stochastic_block_1 (Stochast multiple                  37764     \n",
      "_________________________________________________________________\n",
      "stochastic_block_2 (Stochast multiple                  37764     \n",
      "_________________________________________________________________\n",
      "stochastic_block_3 (Stochast multiple                  37764     \n",
      "_________________________________________________________________\n",
      "stochastic_block_4 (Stochast multiple                  37764     \n",
      "_________________________________________________________________\n",
      "stochastic_block_5 (Stochast multiple                  37764     \n",
      "_________________________________________________________________\n",
      "inp_dropout (Dropout)        multiple                  0         \n",
      "=================================================================\n",
      "Total params: 1,249,834\n",
      "Trainable params: 1,249,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_dm.get_inp_tar_pairs()\n",
    "x, y = next(iter(train_ds))\n",
    "model(x, None, labels=y, training=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create simulated annealing schedule for gumbel softmax tau. We use exponential decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "train_loss = tf.keras.metrics.Mean()\n",
    "valid_loss = tf.keras.metrics.Mean()\n",
    "train_perp = tf.keras.metrics.Mean()\n",
    "valid_perp = tf.keras.metrics.Mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3. Total steps: 8481\n"
     ]
    }
   ],
   "source": [
    "# Define tau schedule, plus must specify total number of global steps\n",
    "EPOCHS = 3\n",
    "tot_steps = int(EPOCHS*ds_size.numpy())\n",
    "\n",
    "tau_is_trainable = False\n",
    "\n",
    "tau = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=2.0,\n",
    "    decay_steps = tot_steps,\n",
    "    decay_rate = 0.1\n",
    ")\n",
    "\n",
    "print(f\"Epochs: {EPOCHS}. Total steps: {tot_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training step and optimizer.\n",
    "\n",
    "learning_rate = CustomSchedule(config['d_model'], 4000)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "@tf.function\n",
    "def train_step(inp, x_mems, labels, tau):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss, mems = model(x, x_mems, labels=labels, training=True, tau=tau)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_perp(tf.math.exp(loss))\n",
    "    return mems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def evaluation_step(x, x_mems, labels, tau):\n",
    "    loss, mems = model(x, x_mems=x_mems, labels=labels, tau=tau, training=False)\n",
    "    perplexity = tf.math.exp(loss)\n",
    "    valid_loss(loss)\n",
    "    valid_perp(perplexity)\n",
    "    return mems\n",
    "\n",
    "def evaluation(dataset, tau):\n",
    "    x_mems = None\n",
    "    for x, lbl in dataset:\n",
    "        x_mems = evaluation_step(x, x_mems, lbl, tau)\n",
    "\n",
    "# @tf.function\n",
    "# def evaluation(dataset, tau):\n",
    "#     mems = None\n",
    "#     for x, lbl in dataset:\n",
    "#         loss, mems = model(x, x_mems=mems, labels=lbl, tau=tau, training=False)\n",
    "#         perplexity = tf.math.exp(loss)\n",
    "#         valid_loss(loss)\n",
    "#         valid_perp(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Checkpoints\n",
    "\n",
    "checkpoint_path = \"./checkpoints/train\"\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    try:\n",
    "        ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "        print ('Latest checkpoint restored!!')\n",
    "    except:\n",
    "        print(\"Model may have changed, could not restore checkpoint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tau untrainable\n",
    "if not tau_is_trainable:\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'tau'):\n",
    "            layer.tau = tf.cast(tf.constant(1.), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Set up TensorBoard\n",
    "\n",
    "%load_ext tensorboard\n",
    "train_log_dir = './logs' + '/train'\n",
    "test_log_dir = './logs' + '/test'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_dm.get_inp_tar_pairs().prefetch(tf.data.AUTOTUNE)\n",
    "valid_ds = valid_dm.get_inp_tar_pairs().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f6d05594fdeaef04\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f6d05594fdeaef04\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------  Epoch 1  ----------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    <ipython-input-448-f7b0885aefec>:9 train_step  *\n        loss, mems = model(x, x_mems, labels=labels, training=True, tau=tau)\n    /Users/jonathankernes/Documents/NLP/transformer-xl/PARtransformer/par_model.py:261 call  *\n        x = self.embed(x)\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__  **\n        outputs = call_fn(inputs, *args, **kwargs)\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/embeddings.py:190 call\n        dtype = K.dtype(inputs)\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:1418 dtype\n        return x.dtype.base_dtype.name\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:798 __getattribute__\n        raise e\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:788 __getattribute__\n        return super(OptimizerV2, self).__getattribute__(name)\n\n    AttributeError: 'RMSprop' object has no attribute 'dtype'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-455-8fd005d892e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mmems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprintBar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    <ipython-input-448-f7b0885aefec>:9 train_step  *\n        loss, mems = model(x, x_mems, labels=labels, training=True, tau=tau)\n    /Users/jonathankernes/Documents/NLP/transformer-xl/PARtransformer/par_model.py:261 call  *\n        x = self.embed(x)\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__  **\n        outputs = call_fn(inputs, *args, **kwargs)\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/embeddings.py:190 call\n        dtype = K.dtype(inputs)\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:1418 dtype\n        return x.dtype.base_dtype.name\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:798 __getattribute__\n        raise e\n    /Users/jonathankernes/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:788 __getattribute__\n        return super(OptimizerV2, self).__getattribute__(name)\n\n    AttributeError: 'RMSprop' object has no attribute 'dtype'\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir ./logs\n",
    "history={'loss':[], 'tau':[]}\n",
    "glob_step = 0\n",
    "num_batches = train_dm.ds_size.numpy()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    print('-'*10,f' Epoch {epoch+1} ', '-'*10)\n",
    "    start = time.time()\n",
    "    train_loss.reset_states()\n",
    "    mems = None\n",
    "    for step, (inp, lbl) in enumerate(train_ds):\n",
    "        \n",
    "        mems = train_step(inp, mems, lbl, tau(glob_step))\n",
    "        diff = (time.time()-start)/(step+1)\n",
    "        printBar(step, num_batches, diff, train_loss.result().numpy())\n",
    "                \n",
    "        history['loss'].append(train_loss.result().numpy())\n",
    "        history['tau'].append(tau(glob_step).numpy())\n",
    "        \n",
    "        with train_summary_writer.as_default():\n",
    "            tf.summary.scalar('train_loss', train_loss.result(), step=glob_step)\n",
    "            tf.summary.scalar('train_perp', train_perp.result(), step=glob_step)\n",
    "            tf.summary.scalar('tau', tau(glob_step), step=glob_step)        \n",
    "        glob_step += 1\n",
    "     \n",
    "    evaluation(valid_ds, tau(glob_step))\n",
    "    with test_summary_writer.as_default():\n",
    "        tf.summary.scalar('valid_loss', valid_loss.result(), step=glob_step)\n",
    "        tf.summary.scalar('valid_perp', valid_perp.result(), step=glob_step)\n",
    "    \n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print(f'Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.0>"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau(tf.Variable(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbbd98872e0>]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: [0.32119352 0.32047126 0.35673234]\n",
      "Layer 2: [0.3197162  0.34020415 0.35368592]\n",
      "Layer 3: [0.35318667 0.28377616 0.34028876]\n",
      "Layer 4: [0.3391504  0.30977973 0.3718491 ]\n",
      "Layer 1: 1.0\n",
      "Layer 2: 1.0\n",
      "Layer 3: 1.0\n",
      "Layer 4: 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,6):\n",
    "    print(f\"Layer {i-1}: {model.layers[i].pi.numpy()}\")\n",
    "    \n",
    "for i in range(2,6):\n",
    "    print(f\"Layer {i-1}: {model.layers[i].tau.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpointing and model saving\n",
    "\n",
    "# Initializing a checkpoint manager\n",
    "opt = tf.keras.optimizers.Adam(0.1)\n",
    "dataset = toy_dataset()\n",
    "iterator = iter(dataset)\n",
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=net, iterator=iterator)\n",
    "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)\n",
    "\n",
    "\n",
    "# Restoring from a previous checkpoint\n",
    "ckpt.restore(manager.latest_checkpoint)\n",
    "if manager.latest_checkpoint:\n",
    "    print(f\"Restored from {manager.latest_checkpoint})\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")\n",
    "\n",
    "# Keep track of global step manually in the checkpoint\n",
    "ckpt.step.assign_add(1)\n",
    "if int(ckpt.step) % 10 == 0:\n",
    "  save_path = manager.save()\n",
    "  print(f\"Saved checkpoint for step {int(ckpt.step)}: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 144x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.random.rand(5,3)\n",
    "x /= np.sum(x, axis=1, keepdims=True)\n",
    "fig = plt.figure(figsize=(2, 6))\n",
    "# ax = fig.add_subplot(1, 1, 1)\n",
    "# # plot the attention weights\n",
    "# ax.matshow(x, cmap='viridis')\n",
    "# fontdict = {'fontsize': 20}\n",
    "# ax.set_xticks(range(x.shape[1]))\n",
    "# ax.set_yticks(range(x.shape[0]))\n",
    "# ax.set_xticklabels(['Attn', 'FFN', 'Id'], fontdict=fontdict, rotation=45)\n",
    "# ax.set_yticklabels([i for i in range(x.shape[1])], fontdict=fontdict)\n",
    "# ax.set_xlabel(f'Block type probability {1}')\n",
    "# ax.set_ylabel(f'Layer')\n",
    "# plot the attention weights\n",
    "plt.matshow(x, cmap='viridis')\n",
    "fontdict = {'fontsize': 20}\n",
    "plt.xticks(range(x.shape[1]), ['Attention', 'Dense', 'Identity'], rotation=15, size=14)\n",
    "plt.yticks(range(x.shape[0]), range(x.shape[0]))\n",
    "plt.xlabel(f'Block type probability', size=16)\n",
    "plt.ylabel(f'Layer', size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None]\n",
      "[None, None, 5, None]\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def train_step(inp, x_mems, labels, tau):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss, mems = model(x, x_mems=x_mems, labels=labels, training=True, tau=tau)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_perp(tf.math.exp(loss))\n",
    "    return mems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, mems, labels):\n",
    "    loss, mems = model(inp, mems, labels, 2.0, True, None)\n",
    "    return mems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_dm.get_inp_tar_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, lbl = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = model(inp, None, lbl, 2.0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction train_step(inp, mems=None, labels) at 0x7FBB6D8579A0>"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_step.get_concrete_function(inp, None, lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=int64, numpy=0>\n",
      "<tf.Variable 'Variable:0' shape=() dtype=int64, numpy=1>\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(0, dtype=tf.int64)\n",
    "print(x)\n",
    "x.assign_add(1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train_step(inp, inp, labels=lbl, tau=2.0)\n",
    "print(train_step.pretty_printed_concrete_signatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on PARTransformerXL in module par_model object:\n",
      "\n",
      "class PARTransformerXL(tensorflow.python.keras.engine.training.Model)\n",
      " |  PARTransformerXL(*args, **kwargs)\n",
      " |  \n",
      " |  `Model` groups layers into an object with training and inference features.\n",
      " |  \n",
      " |  Arguments:\n",
      " |      inputs: The input(s) of the model: a `keras.Input` object or list of\n",
      " |          `keras.Input` objects.\n",
      " |      outputs: The output(s) of the model. See Functional API example below.\n",
      " |      name: String, the name of the model.\n",
      " |  \n",
      " |  There are two ways to instantiate a `Model`:\n",
      " |  \n",
      " |  1 - With the \"Functional API\", where you start from `Input`,\n",
      " |  you chain layer calls to specify the model's forward pass,\n",
      " |  and finally you create your model from inputs and outputs:\n",
      " |  \n",
      " |  ```python\n",
      " |  import tensorflow as tf\n",
      " |  \n",
      " |  inputs = tf.keras.Input(shape=(3,))\n",
      " |  x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)\n",
      " |  outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)\n",
      " |  model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
      " |  ```\n",
      " |  \n",
      " |  2 - By subclassing the `Model` class: in that case, you should define your\n",
      " |  layers in `__init__` and you should implement the model's forward pass\n",
      " |  in `call`.\n",
      " |  \n",
      " |  ```python\n",
      " |  import tensorflow as tf\n",
      " |  \n",
      " |  class MyModel(tf.keras.Model):\n",
      " |  \n",
      " |    def __init__(self):\n",
      " |      super(MyModel, self).__init__()\n",
      " |      self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
      " |      self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\n",
      " |  \n",
      " |    def call(self, inputs):\n",
      " |      x = self.dense1(inputs)\n",
      " |      return self.dense2(x)\n",
      " |  \n",
      " |  model = MyModel()\n",
      " |  ```\n",
      " |  \n",
      " |  If you subclass `Model`, you can optionally have\n",
      " |  a `training` argument (boolean) in `call`, which you can use to specify\n",
      " |  a different behavior in training and inference:\n",
      " |  \n",
      " |  ```python\n",
      " |  import tensorflow as tf\n",
      " |  \n",
      " |  class MyModel(tf.keras.Model):\n",
      " |  \n",
      " |    def __init__(self):\n",
      " |      super(MyModel, self).__init__()\n",
      " |      self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
      " |      self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\n",
      " |      self.dropout = tf.keras.layers.Dropout(0.5)\n",
      " |  \n",
      " |    def call(self, inputs, training=False):\n",
      " |      x = self.dense1(inputs)\n",
      " |      if training:\n",
      " |        x = self.dropout(x, training=training)\n",
      " |      return self.dense2(x)\n",
      " |  \n",
      " |  model = MyModel()\n",
      " |  ```\n",
      " |  \n",
      " |  Once the model is created, you can config the model with losses and metrics\n",
      " |  with `model.compile()`, train the model with `model.fit()`, or use the model\n",
      " |  to do prediction with `model.predict()`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      PARTransformerXL\n",
      " |      tensorflow.python.keras.engine.training.Model\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      tensorflow.python.keras.utils.version_utils.LayerVersionSelector\n",
      " |      tensorflow.python.keras.utils.version_utils.ModelVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, d_model, num_heads, max_position, d_ffn, num_layers, mem_len, vocab_size, dropout_rate=0.1, cutoffs=None, proj_factor=4, proj_dims=None, **kwargs)\n",
      " |  \n",
      " |  call(self, x, x_mems=None, tau=None, labels=None, training=None, pad_mask=None)\n",
      " |      Calls the model on new inputs.\n",
      " |      \n",
      " |      In this case `call` just reapplies\n",
      " |      all ops in the graph to the new inputs\n",
      " |      (e.g. build a new computational graph from the provided inputs).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: A tensor or list of tensors.\n",
      " |          training: Boolean or boolean scalar tensor, indicating whether to run\n",
      " |            the `Network` in training mode or inference mode.\n",
      " |          mask: A mask or list of masks. A mask can be\n",
      " |              either a tensor or None (no mask).\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor if there is a single output, or\n",
      " |          a list of tensors if there are more than one outputs.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Builds the model based on input shapes received.\n",
      " |      \n",
      " |      This is to be used for subclassed models, which do not know at instantiation\n",
      " |      time what their inputs look like.\n",
      " |      \n",
      " |      This method only exists for users who want to call `model.build()` in a\n",
      " |      standalone way (as a substitute for calling the model on real data to\n",
      " |      build it). It will never be called by the framework (and thus it will\n",
      " |      never throw unexpected errors in an unrelated workflow).\n",
      " |      \n",
      " |      Args:\n",
      " |       input_shape: Single tuple, TensorShape, or list/dict of shapes, where\n",
      " |           shapes are tuples, integers, or TensorShapes.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError:\n",
      " |          1. In case of invalid user-provided data (not of type tuple,\n",
      " |             list, TensorShape, or dict).\n",
      " |          2. If the model requires call arguments that are agnostic\n",
      " |             to the input shapes (positional or kwarg in call signature).\n",
      " |          3. If not all layers were properly built.\n",
      " |          4. If float type inputs are not supported within the layers.\n",
      " |      \n",
      " |        In each of these cases, the user should build their model by calling it\n",
      " |        on real tensor data.\n",
      " |  \n",
      " |  compile(self, optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, weighted_metrics=None, run_eagerly=None, steps_per_execution=None, **kwargs)\n",
      " |      Configures the model for training.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          optimizer: String (name of optimizer) or optimizer instance. See\n",
      " |            `tf.keras.optimizers`.\n",
      " |          loss: String (name of objective function), objective function or\n",
      " |            `tf.keras.losses.Loss` instance. See `tf.keras.losses`. An objective\n",
      " |            function is any callable with the signature `loss = fn(y_true,\n",
      " |            y_pred)`, where y_true = ground truth values with shape =\n",
      " |            `[batch_size, d0, .. dN]`, except sparse loss functions such as sparse\n",
      " |            categorical crossentropy where shape = `[batch_size, d0, .. dN-1]`.\n",
      " |            y_pred = predicted values with shape = `[batch_size, d0, .. dN]`. It\n",
      " |            returns a weighted loss float tensor. If a custom `Loss` instance is\n",
      " |            used and reduction is set to NONE, return value has the shape\n",
      " |            [batch_size, d0, .. dN-1] ie. per-sample or per-timestep loss values;\n",
      " |            otherwise, it is a scalar. If the model has multiple outputs, you can\n",
      " |            use a different loss on each output by passing a dictionary or a list\n",
      " |            of losses. The loss value that will be minimized by the model will\n",
      " |            then be the sum of all individual losses.\n",
      " |          metrics: List of metrics to be evaluated by the model during training\n",
      " |            and testing. Each of this can be a string (name of a built-in\n",
      " |            function), function or a `tf.keras.metrics.Metric` instance. See\n",
      " |            `tf.keras.metrics`. Typically you will use `metrics=['accuracy']`. A\n",
      " |            function is any callable with the signature `result = fn(y_true,\n",
      " |            y_pred)`. To specify different metrics for different outputs of a\n",
      " |            multi-output model, you could also pass a dictionary, such as\n",
      " |              `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
      " |                You can also pass a list (len = len(outputs)) of lists of metrics\n",
      " |                such as `metrics=[['accuracy'], ['accuracy', 'mse']]` or\n",
      " |                `metrics=['accuracy', ['accuracy', 'mse']]`. When you pass the\n",
      " |                strings 'accuracy' or 'acc', we convert this to one of\n",
      " |                `tf.keras.metrics.BinaryAccuracy`,\n",
      " |                `tf.keras.metrics.CategoricalAccuracy`,\n",
      " |                `tf.keras.metrics.SparseCategoricalAccuracy` based on the loss\n",
      " |                function used and the model output shape. We do a similar\n",
      " |                conversion for the strings 'crossentropy' and 'ce' as well.\n",
      " |          loss_weights: Optional list or dictionary specifying scalar coefficients\n",
      " |            (Python floats) to weight the loss contributions of different model\n",
      " |            outputs. The loss value that will be minimized by the model will then\n",
      " |            be the *weighted sum* of all individual losses, weighted by the\n",
      " |            `loss_weights` coefficients.\n",
      " |              If a list, it is expected to have a 1:1 mapping to the model's\n",
      " |                outputs. If a dict, it is expected to map output names (strings)\n",
      " |                to scalar coefficients.\n",
      " |          weighted_metrics: List of metrics to be evaluated and weighted by\n",
      " |            sample_weight or class_weight during training and testing.\n",
      " |          run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`'s\n",
      " |            logic will not be wrapped in a `tf.function`. Recommended to leave\n",
      " |            this as `None` unless your `Model` cannot be run inside a\n",
      " |            `tf.function`.\n",
      " |          steps_per_execution: Int. Defaults to 1. The number of batches to\n",
      " |            run during each `tf.function` call. Running multiple batches\n",
      " |            inside a single `tf.function` call can greatly improve performance\n",
      " |            on TPUs or small models with a large Python overhead.\n",
      " |            At most, one full epoch will be run each\n",
      " |            execution. If a number larger than the size of the epoch is passed,\n",
      " |            the execution will be truncated to the size of the epoch.\n",
      " |            Note that if `steps_per_execution` is set to `N`,\n",
      " |            `Callback.on_batch_begin` and `Callback.on_batch_end` methods\n",
      " |            will only be called every `N` batches\n",
      " |            (i.e. before/after each `tf.function` execution).\n",
      " |          **kwargs: Arguments supported for backwards compatibility only.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid arguments for\n",
      " |              `optimizer`, `loss` or `metrics`.\n",
      " |  \n",
      " |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False)\n",
      " |      Returns the loss value & metrics values for the model in test mode.\n",
      " |      \n",
      " |      Computation is done in batches (see the `batch_size` arg.)\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset. Should return a tuple\n",
      " |              of either `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      " |              or `(inputs, targets, sample_weights)`.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
      " |            for iterator-like inputs` section of `Model.fit`.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
      " |            `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`\n",
      " |            should not be specified (since targets will be obtained from the\n",
      " |            iterator/dataset).\n",
      " |          batch_size: Integer or `None`. Number of samples per batch of\n",
      " |            computation. If unspecified, `batch_size` will default to 32. Do not\n",
      " |            specify the `batch_size` if your data is in the form of a dataset,\n",
      " |            generators, or `keras.utils.Sequence` instances (since they generate\n",
      " |            batches).\n",
      " |          verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\n",
      " |          sample_weight: Optional Numpy array of weights for the test samples,\n",
      " |            used for weighting the loss function. You can either pass a flat (1D)\n",
      " |            Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples), or in the case of\n",
      " |                temporal data, you can pass a 2D array with shape `(samples,\n",
      " |                sequence_length)`, to apply a different weight to every timestep\n",
      " |                of every sample. This argument is not supported when `x` is a\n",
      " |                dataset, instead pass sample weights as the third element of `x`.\n",
      " |          steps: Integer or `None`. Total number of steps (batches of samples)\n",
      " |            before declaring the evaluation round finished. Ignored with the\n",
      " |            default value of `None`. If x is a `tf.data` dataset and `steps` is\n",
      " |            None, 'evaluate' will run until the dataset is exhausted. This\n",
      " |            argument is not supported with array inputs.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances. List of\n",
      " |            callbacks to apply during evaluation. See\n",
      " |            [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |            input only. Maximum size for the generator queue. If unspecified,\n",
      " |            `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |            only. Maximum number of processes to spin up when using process-based\n",
      " |            threading. If unspecified, `workers` will default to 1. If 0, will\n",
      " |            execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |            `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |            threading. If unspecified, `use_multiprocessing` will default to\n",
      " |            `False`. Note that because this implementation relies on\n",
      " |            multiprocessing, you should not pass non-picklable arguments to the\n",
      " |            generator as they can't be passed easily to children processes.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.evaluate` is wrapped in `tf.function`.\n",
      " |          ValueError: in case of invalid arguments.\n",
      " |  \n",
      " |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Evaluates the model on a data generator.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.evaluate` now supports generators, so there is no longer any need\n",
      " |        to use this endpoint.\n",
      " |  \n",
      " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset. Should return a tuple\n",
      " |              of either `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      " |              or `(inputs, targets, sample_weights)`.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given below.\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      " |            tensor targets, or inversely). If `x` is a dataset, generator,\n",
      " |            or `keras.utils.Sequence` instance, `y` should\n",
      " |            not be specified (since targets will be obtained from `x`).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire `x` and `y`\n",
      " |              data provided.\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |              Note that the progress bar is not particularly useful when\n",
      " |              logged to a file, so verbose=2 is recommended when not running\n",
      " |              interactively (eg, in a production environment).\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See `tf.keras.callbacks`. Note `tf.keras.callbacks.ProgbarLogger`\n",
      " |              and `tf.keras.callbacks.History` callbacks are created automatically\n",
      " |              and need not be passed into `model.fit`.\n",
      " |              `tf.keras.callbacks.ProgbarLogger` is created or not based on\n",
      " |              `verbose` argument to `model.fit`.\n",
      " |          validation_split: Float between 0 and 1.\n",
      " |              Fraction of the training data to be used as validation data.\n",
      " |              The model will set apart this fraction of the training data,\n",
      " |              will not train on it, and will evaluate\n",
      " |              the loss and any model metrics\n",
      " |              on this data at the end of each epoch.\n",
      " |              The validation data is selected from the last samples\n",
      " |              in the `x` and `y` data provided, before shuffling. This argument is\n",
      " |              not supported when `x` is a dataset, generator or\n",
      " |             `keras.utils.Sequence` instance.\n",
      " |          validation_data: Data on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data. Thus, note the fact\n",
      " |              that the validation loss of data provided using `validation_split`\n",
      " |              or `validation_data` is not affected by regularization layers like\n",
      " |              noise and dropout.\n",
      " |              `validation_data` will override `validation_split`.\n",
      " |              `validation_data` could be:\n",
      " |                - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
      " |                - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
      " |                - dataset\n",
      " |              For the first two cases, `batch_size` must be provided.\n",
      " |              For the last case, `validation_steps` could be provided.\n",
      " |              Note that `validation_data` does not support all the data types that\n",
      " |              are supported in `x`, eg, dict, generator or `keras.utils.Sequence`.\n",
      " |          shuffle: Boolean (whether to shuffle the training data\n",
      " |              before each epoch) or str (for 'batch'). This argument is ignored\n",
      " |              when `x` is a generator. 'batch' is a special option for dealing\n",
      " |              with the limitations of HDF5 data; it shuffles in batch-sized\n",
      " |              chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only).\n",
      " |              This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from\n",
      " |              an under-represented class.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the training samples, used for weighting the loss function\n",
      " |              (during training only). You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample. This\n",
      " |              argument is not supported when `x` is a dataset, generator, or\n",
      " |             `keras.utils.Sequence` instance, instead provide the sample_weights\n",
      " |              as the third element of `x`.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |          steps_per_epoch: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring one epoch finished and starting the\n",
      " |              next epoch. When training with input tensors such as\n",
      " |              TensorFlow data tensors, the default `None` is equal to\n",
      " |              the number of samples in your dataset divided by\n",
      " |              the batch size, or 1 if that cannot be determined. If x is a\n",
      " |              `tf.data` dataset, and 'steps_per_epoch'\n",
      " |              is None, the epoch will run until the input dataset is exhausted.\n",
      " |              When passing an infinitely repeating dataset, you must specify the\n",
      " |              `steps_per_epoch` argument. This argument is not supported with\n",
      " |              array inputs.\n",
      " |          validation_steps: Only relevant if `validation_data` is provided and\n",
      " |              is a `tf.data` dataset. Total number of steps (batches of\n",
      " |              samples) to draw before stopping when performing validation\n",
      " |              at the end of every epoch. If 'validation_steps' is None, validation\n",
      " |              will run until the `validation_data` dataset is exhausted. In the\n",
      " |              case of an infinitely repeated dataset, it will run into an\n",
      " |              infinite loop. If 'validation_steps' is specified and only part of\n",
      " |              the dataset will be consumed, the evaluation will start from the\n",
      " |              beginning of the dataset at each epoch. This ensures that the same\n",
      " |              validation samples are used every time.\n",
      " |          validation_batch_size: Integer or `None`.\n",
      " |              Number of samples per validation batch.\n",
      " |              If unspecified, will default to `batch_size`.\n",
      " |              Do not specify the `validation_batch_size` if your data is in the\n",
      " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          validation_freq: Only relevant if validation data is provided. Integer\n",
      " |              or `collections_abc.Container` instance (e.g. list, tuple, etc.).\n",
      " |              If an integer, specifies how many training epochs to run before a\n",
      " |              new validation run is performed, e.g. `validation_freq=2` runs\n",
      " |              validation every 2 epochs. If a Container, specifies the epochs on\n",
      " |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
      " |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up\n",
      " |              when using process-based threading. If unspecified, `workers`\n",
      " |              will default to 1. If 0, will execute the generator on the main\n",
      " |              thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      Unpacking behavior for iterator-like inputs:\n",
      " |          A common pattern is to pass a tf.data.Dataset, generator, or\n",
      " |        tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
      " |        yield not only features (x) but optionally targets (y) and sample weights.\n",
      " |        Keras requires that the output of such iterator-likes be unambiguous. The\n",
      " |        iterator should return a tuple of length 1, 2, or 3, where the optional\n",
      " |        second and third elements will be used for y and sample_weight\n",
      " |        respectively. Any other type provided will be wrapped in a length one\n",
      " |        tuple, effectively treating everything as 'x'. When yielding dicts, they\n",
      " |        should still adhere to the top-level tuple structure.\n",
      " |        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
      " |        features, targets, and weights from the keys of a single dict.\n",
      " |          A notable unsupported data type is the namedtuple. The reason is that\n",
      " |        it behaves like both an ordered datatype (tuple) and a mapping\n",
      " |        datatype (dict). So given a namedtuple of the form:\n",
      " |            `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
      " |        it is ambiguous whether to reverse the order of the elements when\n",
      " |        interpreting the value. Even worse is a tuple of the form:\n",
      " |            `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
      " |        where it is unclear if the tuple was intended to be unpacked into x, y,\n",
      " |        and sample_weight or passed through as a single element to `x`. As a\n",
      " |        result the data processing code will simply raise a ValueError if it\n",
      " |        encounters a namedtuple. (Along with instructions to remedy the issue.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: 1. If the model was never compiled or,\n",
      " |          2. If `model.fit` is  wrapped in `tf.function`.\n",
      " |      \n",
      " |          ValueError: In case of mismatch between the provided input data\n",
      " |              and what the model expects or when the input data is empty.\n",
      " |  \n",
      " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
      " |      Fits the model on data yielded batch-by-batch by a Python generator.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.fit` now supports generators, so there is no longer any need to use\n",
      " |        this endpoint.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      If `name` and `index` are both provided, `index` will take precedence.\n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid layer name or index.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Retrieves the weights of the model.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A flat list of Numpy arrays.\n",
      " |  \n",
      " |  load_weights(self, filepath, by_name=False, skip_mismatch=False, options=None)\n",
      " |      Loads all layer weights, either from a TensorFlow or an HDF5 weight file.\n",
      " |      \n",
      " |      If `by_name` is False weights are loaded based on the network's\n",
      " |      topology. This means the architecture should be the same as when the weights\n",
      " |      were saved.  Note that layers that don't have weights are not taken into\n",
      " |      account in the topological ordering, so adding or removing layers is fine as\n",
      " |      long as they don't have weights.\n",
      " |      \n",
      " |      If `by_name` is True, weights are loaded into layers only if they share the\n",
      " |      same name. This is useful for fine-tuning or transfer-learning models where\n",
      " |      some of the layers have changed.\n",
      " |      \n",
      " |      Only topological loading (`by_name=False`) is supported when loading weights\n",
      " |      from the TensorFlow format. Note that topological loading differs slightly\n",
      " |      between TensorFlow and HDF5 formats for user-defined classes inheriting from\n",
      " |      `tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the\n",
      " |      TensorFlow format loads based on the object-local names of attributes to\n",
      " |      which layers are assigned in the `Model`'s constructor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String, path to the weights file to load. For weight files in\n",
      " |              TensorFlow format, this is the file prefix (the same as was passed\n",
      " |              to `save_weights`).\n",
      " |          by_name: Boolean, whether to load weights by name or by topological\n",
      " |              order. Only topological loading is supported for weight files in\n",
      " |              TensorFlow format.\n",
      " |          skip_mismatch: Boolean, whether to skip loading of layers where there is\n",
      " |              a mismatch in the number of weights, or a mismatch in the shape of\n",
      " |              the weight (only valid when `by_name=True`).\n",
      " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
      " |              options for loading weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          When loading a weight file in TensorFlow format, returns the same status\n",
      " |          object as `tf.train.Checkpoint.restore`. When graph building, restore\n",
      " |          ops are run automatically as soon as the network is built (on first call\n",
      " |          for user-defined classes inheriting from `Model`, immediately if it is\n",
      " |          already built).\n",
      " |      \n",
      " |          When loading weights in HDF5 format, returns `None`.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If h5py is not available and the weight file is in HDF5\n",
      " |              format.\n",
      " |          ValueError: If `skip_mismatch` is set to `True` when `by_name` is\n",
      " |            `False`.\n",
      " |  \n",
      " |  make_predict_function(self)\n",
      " |      Creates a function that executes one step of inference.\n",
      " |      \n",
      " |      This method can be overridden to support custom inference logic.\n",
      " |      This method is called by `Model.predict` and `Model.predict_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
      " |      logic to `Model.predict_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.predict` or\n",
      " |      `Model.predict_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return the outputs of the `Model`.\n",
      " |  \n",
      " |  make_test_function(self)\n",
      " |      Creates a function that executes one step of evaluation.\n",
      " |      \n",
      " |      This method can be overridden to support custom evaluation logic.\n",
      " |      This method is called by `Model.evaluate` and `Model.test_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
      " |      logic to `Model.test_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.evaluate` or\n",
      " |      `Model.test_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
      " |        be passed to `tf.keras.Callbacks.on_test_batch_end`.\n",
      " |  \n",
      " |  make_train_function(self)\n",
      " |      Creates a function that executes one step of training.\n",
      " |      \n",
      " |      This method can be overridden to support custom training logic.\n",
      " |      This method is called by `Model.fit` and `Model.train_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual training\n",
      " |      logic to `Model.train_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.fit` or\n",
      " |      `Model.train_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
      " |        be passed to `tf.keras.Callbacks.on_train_batch_end`, such as\n",
      " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Generates output predictions for the input samples.\n",
      " |      \n",
      " |      Computation is done in batches. This method is designed for performance in\n",
      " |      large scale inputs. For small amount of inputs that fit in one batch,\n",
      " |      directly using `__call__` is recommended for faster execution, e.g.,\n",
      " |      `model(x)`, or `model(x, training=False)` if you have layers such as\n",
      " |      `tf.keras.layers.BatchNormalization` that behaves differently during\n",
      " |      inference. Also, note the fact that test loss is not affected by\n",
      " |      regularization layers like noise and dropout.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input samples. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A `tf.data` dataset.\n",
      " |            - A generator or `keras.utils.Sequence` instance.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
      " |            for iterator-like inputs` section of `Model.fit`.\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per batch.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of dataset, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          verbose: Verbosity mode, 0 or 1.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              before declaring the prediction round finished.\n",
      " |              Ignored with the default value of `None`. If x is a `tf.data`\n",
      " |              dataset and `steps` is None, `predict` will\n",
      " |              run until the input dataset is exhausted.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during prediction.\n",
      " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up when using\n",
      " |              process-based threading. If unspecified, `workers` will default\n",
      " |              to 1. If 0, will execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`. Note that Model.predict uses the same interpretation rules as\n",
      " |      `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all\n",
      " |      three methods.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.predict` is wrapped in `tf.function`.\n",
      " |          ValueError: In case of mismatch between the provided\n",
      " |              input data and the model's expectations,\n",
      " |              or in case a stateful model receives a number of samples\n",
      " |              that is not a multiple of the batch size.\n",
      " |  \n",
      " |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Generates predictions for the input samples from a data generator.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.predict` now supports generators, so there is no longer any need\n",
      " |        to use this endpoint.\n",
      " |  \n",
      " |  predict_on_batch(self, x)\n",
      " |      Returns predictions for a single batch of samples.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
      " |            of arrays (in case the model has multiple inputs). - A TensorFlow\n",
      " |            tensor, or a list of tensors (in case the model has multiple inputs).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.predict_on_batch` is wrapped in `tf.function`.\n",
      " |          ValueError: In case of mismatch between given number of inputs and\n",
      " |            expectations of the model.\n",
      " |  \n",
      " |  predict_step(self, data)\n",
      " |      The logic for one inference step.\n",
      " |      \n",
      " |      This method can be overridden to support custom inference logic.\n",
      " |      This method is called by `Model.make_predict_function`.\n",
      " |      \n",
      " |      This method should contain the mathematical logic for one step of inference.\n",
      " |      This typically includes the forward pass.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_predict_function`, which can also be overridden.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The result of one inference step, typically the output of calling the\n",
      " |        `Model` on data.\n",
      " |  \n",
      " |  reset_metrics(self)\n",
      " |      Resets the state of all the metrics in the model.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> _ = model.fit(x, y, verbose=0)\n",
      " |      >>> assert all(float(m.result()) for m in model.metrics)\n",
      " |      \n",
      " |      >>> model.reset_metrics()\n",
      " |      >>> assert all(float(m.result()) == 0 for m in model.metrics)\n",
      " |  \n",
      " |  reset_states(self)\n",
      " |  \n",
      " |  save(self, filepath, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None, save_traces=True)\n",
      " |      Saves the model to Tensorflow SavedModel or a single HDF5 file.\n",
      " |      \n",
      " |      Please see `tf.keras.models.save_model` or the\n",
      " |      [Serialization and Saving guide](https://keras.io/guides/serialization_and_saving/)\n",
      " |      for details.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String, PathLike, path to SavedModel or H5 file to save the\n",
      " |              model.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          include_optimizer: If True, save optimizer's state together.\n",
      " |          save_format: Either `'tf'` or `'h5'`, indicating whether to save the\n",
      " |              model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X,\n",
      " |              and 'h5' in TF 1.X.\n",
      " |          signatures: Signatures to save with the SavedModel. Applicable to the\n",
      " |              'tf' format only. Please see the `signatures` argument in\n",
      " |              `tf.saved_model.save` for details.\n",
      " |          options: (only applies to SavedModel format)\n",
      " |              `tf.saved_model.SaveOptions` object that specifies options for\n",
      " |              saving to SavedModel.\n",
      " |          save_traces: (only applies to SavedModel format) When enabled, the\n",
      " |              SavedModel will store the function traces for each layer. This\n",
      " |              can be disabled, so that only the configs of each layer are stored.\n",
      " |              Defaults to `True`. Disabling this will decrease serialization time\n",
      " |              and reduce file size, but it requires that all custom layers/models\n",
      " |              implement a `get_config()` method.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      from keras.models import load_model\n",
      " |      \n",
      " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
      " |      del model  # deletes the existing model\n",
      " |      \n",
      " |      # returns a compiled model\n",
      " |      # identical to the previous one\n",
      " |      model = load_model('my_model.h5')\n",
      " |      ```\n",
      " |  \n",
      " |  save_weights(self, filepath, overwrite=True, save_format=None, options=None)\n",
      " |      Saves all layer weights.\n",
      " |      \n",
      " |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
      " |      argument.\n",
      " |      \n",
      " |      When saving in HDF5 format, the weight file has:\n",
      " |        - `layer_names` (attribute), a list of strings\n",
      " |            (ordered names of model layers).\n",
      " |        - For every layer, a `group` named `layer.name`\n",
      " |            - For every such layer group, a group attribute `weight_names`,\n",
      " |                a list of strings\n",
      " |                (ordered names of weights tensor of the layer).\n",
      " |            - For every weight in the layer, a dataset\n",
      " |                storing the weight value, named after the weight tensor.\n",
      " |      \n",
      " |      When saving in TensorFlow format, all objects referenced by the network are\n",
      " |      saved in the same format as `tf.train.Checkpoint`, including any `Layer`\n",
      " |      instances or `Optimizer` instances assigned to object attributes. For\n",
      " |      networks constructed from inputs and outputs using `tf.keras.Model(inputs,\n",
      " |      outputs)`, `Layer` instances used by the network are tracked/saved\n",
      " |      automatically. For user-defined classes which inherit from `tf.keras.Model`,\n",
      " |      `Layer` instances must be assigned to object attributes, typically in the\n",
      " |      constructor. See the documentation of `tf.train.Checkpoint` and\n",
      " |      `tf.keras.Model` for details.\n",
      " |      \n",
      " |      While the formats are the same, do not mix `save_weights` and\n",
      " |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be\n",
      " |      loaded using `Model.load_weights`. Checkpoints saved using\n",
      " |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
      " |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
      " |      `save_weights` for training checkpoints.\n",
      " |      \n",
      " |      The TensorFlow format matches objects and variables by starting at a root\n",
      " |      object, `self` for `save_weights`, and greedily matching attribute\n",
      " |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this\n",
      " |      is the `Checkpoint` even if the `Checkpoint` has a model attached. This\n",
      " |      means saving a `tf.keras.Model` using `save_weights` and loading into a\n",
      " |      `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match\n",
      " |      the `Model`'s variables. See the [guide to training\n",
      " |      checkpoints](https://www.tensorflow.org/guide/checkpoint) for details\n",
      " |      on the TensorFlow format.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String or PathLike, path to the file to save the weights to.\n",
      " |              When saving in TensorFlow format, this is the prefix used for\n",
      " |              checkpoint files (multiple files are generated). Note that the '.h5'\n",
      " |              suffix causes weights to be saved in HDF5 format.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
      " |              '.keras' will default to HDF5 if `save_format` is `None`. Otherwise\n",
      " |              `None` defaults to 'tf'.\n",
      " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
      " |              options for saving weights.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If h5py is not available when attempting to save in HDF5\n",
      " |              format.\n",
      " |          ValueError: For invalid/unknown format arguments.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          line_length: Total length of printed lines\n",
      " |              (e.g. set this to adapt the display to different\n",
      " |              terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements\n",
      " |              in each line. If not provided,\n",
      " |              defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use. Defaults to `print`.\n",
      " |              It will be called on each line of the summary.\n",
      " |              You can set it to a custom function\n",
      " |              in order to capture the string summary.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if `summary()` is called before the model is built.\n",
      " |  \n",
      " |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True, return_dict=False)\n",
      " |      Test the model on a single batch of samples.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
      " |            of arrays (in case the model has multiple inputs). - A TensorFlow\n",
      " |            tensor, or a list of tensors (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors, if\n",
      " |            the model has named inputs.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case of\n",
      " |            temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.test_on_batch` is wrapped in `tf.function`.\n",
      " |          ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  test_step(self, data)\n",
      " |      The logic for one evaluation step.\n",
      " |      \n",
      " |      This method can be overridden to support custom evaluation logic.\n",
      " |      This method is called by `Model.make_test_function`.\n",
      " |      \n",
      " |      This function should contain the mathematical logic for one step of\n",
      " |      evaluation.\n",
      " |      This typically includes the forward pass, loss calculation, and metrics\n",
      " |      updates.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_test_function`, which can also be overridden.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `dict` containing values that will be passed to\n",
      " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
      " |        values of the `Model`'s metrics are returned.\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a JSON save file, use\n",
      " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON string.\n",
      " |  \n",
      " |  to_yaml(self, **kwargs)\n",
      " |      Returns a yaml string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a yaml save file, use\n",
      " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
      " |      \n",
      " |      `custom_objects` should be a dictionary mapping\n",
      " |      the names of custom losses / layers / etc to the corresponding\n",
      " |      functions / classes.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `yaml.dump()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A YAML string.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: if yaml module is not found.\n",
      " |  \n",
      " |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True, return_dict=False)\n",
      " |      Runs a single gradient update on a single batch of data.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |                if the model has named inputs.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case of\n",
      " |            temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers) to a\n",
      " |            weight (float) to apply to the model's loss for the samples from this\n",
      " |            class during training. This can be useful to tell the model to \"pay\n",
      " |            more attention\" to samples from an under-represented class.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar training loss\n",
      " |          (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If `model.train_on_batch` is wrapped in `tf.function`.\n",
      " |        ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  train_step(self, data)\n",
      " |      The logic for one training step.\n",
      " |      \n",
      " |      This method can be overridden to support custom training logic.\n",
      " |      This method is called by `Model.make_train_function`.\n",
      " |      \n",
      " |      This method should contain the mathematical logic for one step of training.\n",
      " |      This typically includes the forward pass, loss calculation, backpropagation,\n",
      " |      and metric updates.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_train_function`, which can also be overridden.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `dict` containing values that will be passed to\n",
      " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
      " |        values of the `Model`'s metrics are returned. Example:\n",
      " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  from_config(config, custom_objects=None) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  distribute_strategy\n",
      " |      The `tf.distribute.Strategy` this model was created under.\n",
      " |  \n",
      " |  layers\n",
      " |  \n",
      " |  metrics\n",
      " |      Returns the model's metrics added using `compile`, `add_metric` APIs.\n",
      " |      \n",
      " |      Note: Metrics passed to `compile()` are available only after a `keras.Model`\n",
      " |      has been trained/evaluated on actual data.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      []\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> model.fit(x, y)\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      ['loss', 'mae']\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
      " |      >>> output_1 = d(inputs)\n",
      " |      >>> output_2 = d(inputs)\n",
      " |      >>> model = tf.keras.models.Model(\n",
      " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
      " |      >>> model.add_metric(\n",
      " |      ...    tf.reduce_sum(output_2), name='mean', aggregation='mean')\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
      " |      >>> model.fit(x, (y, y))\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
      " |      'out_1_acc', 'mean']\n",
      " |  \n",
      " |  metrics_names\n",
      " |      Returns the model's display labels for all outputs.\n",
      " |      \n",
      " |      Note: `metrics_names` are available only after a `keras.Model` has been\n",
      " |      trained/evaluated on actual data.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      >>> model.metrics_names\n",
      " |      []\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> model.fit(x, y)\n",
      " |      >>> model.metrics_names\n",
      " |      ['loss', 'mae']\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
      " |      >>> output_1 = d(inputs)\n",
      " |      >>> output_2 = d(inputs)\n",
      " |      >>> model = tf.keras.models.Model(\n",
      " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
      " |      >>> model.fit(x, (y, y))\n",
      " |      >>> model.metrics_names\n",
      " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
      " |      'out_1_acc']\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are expected\n",
      " |      to be updated manually in `call()`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  state_updates\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Returns the `updates` from all layers that are stateful.\n",
      " |      \n",
      " |      This is useful for separating training updates and\n",
      " |      state updates, e.g. when we need to update a layer's internal state\n",
      " |      during prediction.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  run_eagerly\n",
      " |      Settable attribute indicating whether the model should run eagerly.\n",
      " |      \n",
      " |      Running eagerly means that your model will be run step by step,\n",
      " |      like Python code. Your model might run slower, but it should become easier\n",
      " |      for you to debug it by stepping into individual layer calls.\n",
      " |      \n",
      " |      By default, we will attempt to compile your model to a static graph to\n",
      " |      deliver the best execution performance.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Boolean, whether the model should run eagerly.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        *args: Positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |            inputs - Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(x))\n",
      " |          self.add_metric(tf.reduce_sum(x), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This is\n",
      " |      because we cannot trace the metric result tensor back to the model's inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result of\n",
      " |          calling a `keras.Metric` instance, it will be aggregated by default\n",
      " |          using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The variable created.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a Dense layer returns a list of two values-- per-output\n",
      " |      weights and the bias value. These can be used to set the weights of another\n",
      " |      Dense layer:\n",
      " |      \n",
      " |      >>> a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b.set_weights(a.get_weights())\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  compute_dtype\n",
      " |      The dtype of the layer's computations.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
      " |      the weights.\n",
      " |      \n",
      " |      Layers automatically cast their inputs to the compute dtype, which causes\n",
      " |      computations and the output to be in the compute dtype as well. This is done\n",
      " |      by the base Layer class in `Layer.__call__`, so you do not have to insert\n",
      " |      these casts if implementing your own layer.\n",
      " |      \n",
      " |      Layers often perform certain internal computations in higher precision when\n",
      " |      `compute_dtype` is float16 or bfloat16 for numeric stability. The output\n",
      " |      will still typically be float16 or bfloat16 in such cases.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The layer's compute dtype.\n",
      " |  \n",
      " |  dtype\n",
      " |      The dtype of the layer weights.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
      " |      dtype of the layer's computations.\n",
      " |  \n",
      " |  dtype_policy\n",
      " |      The dtype policy associated with this layer.\n",
      " |      \n",
      " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> len(model.losses)\n",
      " |      0\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> len(model.losses)\n",
      " |      1\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variable_dtype\n",
      " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
      " |      the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
      " |      of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
      " |      error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x, x_mems=None, labels=None, tau=None, training=None, pad_mask=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for i in range(100):\n",
    "    time.sleep(0.01)\n",
    "    x = 5/np.sqrt(i+1)\n",
    "    diff = (time.time()-start)/(i+1)\n",
    "    printBar(i, 100, diff, x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
